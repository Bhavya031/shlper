{
    "delayTime": 1003,
    "executionTime": 7852,
    "id": "sync-0f644564-57e2-4cde-ba1f-afa8d8053c38-e1",
    "output": {
        "detected_language": "en",
        "device": "cuda",
        "model": "base",
        "segments": [
            {
                "avg_logprob": -0.1543141592920354,
                "compression_ratio": 1.5522388059701493,
                "end": 6.28,
                "id": 1,
                "no_speech_prob": 0.0401611328125,
                "seek": 2766,
                "start": 0,
                "temperature": 0,
                "text": " CUDA, a parallel computing platform that allows you to use your GPU for more than just playing video games.",
                "tokens": [
                    50364,
                    29777,
                    7509,
                    11,
                    257,
                    8952,
                    15866,
                    3663,
                    300,
                    4045,
                    291,
                    281,
                    764,
                    428,
                    18407,
                    337,
                    544,
                    813,
                    445,
                    2433,
                    960,
                    2813,
                    13,
                    50682
                ]
            },
            {
                "avg_logprob": -0.1543141592920354,
                "compression_ratio": 1.5522388059701493,
                "end": 13.32,
                "id": 2,
                "no_speech_prob": 0.0401611328125,
                "seek": 2766,
                "start": 6.4,
                "temperature": 0,
                "text": " Compute Unified Device Architecture was developed by Nvidia in 2007 based on the prior work of Ian Buck and John Nichols.",
                "tokens": [
                    50682,
                    6620,
                    1169,
                    1156,
                    2587,
                    50140,
                    43049,
                    390,
                    4743,
                    538,
                    46284,
                    294,
                    12656,
                    2361,
                    322,
                    264,
                    4059,
                    589,
                    295,
                    19595,
                    22006,
                    293,
                    2619,
                    17102,
                    19385,
                    13,
                    51040
                ]
            },
            {
                "avg_logprob": -0.1543141592920354,
                "compression_ratio": 1.5522388059701493,
                "end": 18.72,
                "id": 3,
                "no_speech_prob": 0.0401611328125,
                "seek": 2766,
                "start": 13.6,
                "temperature": 0,
                "text": " Since then, CUDA has revolutionized the world by allowing humans to compute large blocks of data in parallel,",
                "tokens": [
                    51040,
                    4162,
                    550,
                    11,
                    29777,
                    7509,
                    575,
                    8894,
                    1602,
                    264,
                    1002,
                    538,
                    8293,
                    6255,
                    281,
                    14722,
                    2416,
                    8474,
                    295,
                    1412,
                    294,
                    8952,
                    11,
                    51312
                ]
            },
            {
                "avg_logprob": -0.1543141592920354,
                "compression_ratio": 1.5522388059701493,
                "end": 23.18,
                "id": 4,
                "no_speech_prob": 0.0401611328125,
                "seek": 2766,
                "start": 18.98,
                "temperature": 0,
                "text": " which is unlock the true potential of the deep neural networks behind artificial intelligence.",
                "tokens": [
                    51312,
                    597,
                    307,
                    11634,
                    264,
                    2074,
                    3995,
                    295,
                    264,
                    2452,
                    18161,
                    9590,
                    2261,
                    11677,
                    7599,
                    13,
                    51530
                ]
            },
            {
                "avg_logprob": -0.1543141592920354,
                "compression_ratio": 1.5522388059701493,
                "end": 27.66,
                "id": 5,
                "no_speech_prob": 0.0401611328125,
                "seek": 2766,
                "start": 23.36,
                "temperature": 0,
                "text": " The graphics processing unit, or GPU, is historically used for what the name implies.",
                "tokens": [
                    51530,
                    440,
                    11837,
                    9007,
                    4985,
                    11,
                    420,
                    18407,
                    11,
                    307,
                    16180,
                    1143,
                    337,
                    437,
                    264,
                    1315,
                    18779,
                    13,
                    51758
                ]
            },
            {
                "avg_logprob": -0.18863224637681159,
                "compression_ratio": 1.5736196319018405,
                "end": 28.78,
                "id": 6,
                "no_speech_prob": 0.1822509765625,
                "seek": 5644,
                "start": 27.66,
                "temperature": 0,
                "text": " 2-compute graphics.",
                "tokens": [
                    50364,
                    568,
                    12,
                    21541,
                    1169,
                    11837,
                    13,
                    50442
                ]
            },
            {
                "avg_logprob": -0.18863224637681159,
                "compression_ratio": 1.5736196319018405,
                "end": 34.06,
                "id": 7,
                "no_speech_prob": 0.1822509765625,
                "seek": 5644,
                "start": 29.12,
                "temperature": 0,
                "text": " When you play a game in 1080p at 60fps, you've got over 2 million pixels on the screen that",
                "tokens": [
                    50442,
                    1133,
                    291,
                    862,
                    257,
                    1216,
                    294,
                    24547,
                    79,
                    412,
                    4060,
                    50084,
                    11,
                    291,
                    600,
                    658,
                    670,
                    568,
                    2459,
                    18668,
                    322,
                    264,
                    2568,
                    300,
                    50686
                ]
            },
            {
                "avg_logprob": -0.18863224637681159,
                "compression_ratio": 1.5736196319018405,
                "end": 38.02,
                "id": 8,
                "no_speech_prob": 0.1822509765625,
                "seek": 5644,
                "start": 34.06,
                "temperature": 0,
                "text": " may need to be recalculated after every frame, which requires hardware that can do a lot",
                "tokens": [
                    50686,
                    815,
                    643,
                    281,
                    312,
                    850,
                    304,
                    2444,
                    770,
                    934,
                    633,
                    3920,
                    11,
                    597,
                    7029,
                    8837,
                    300,
                    393,
                    360,
                    257,
                    688,
                    50883
                ]
            },
            {
                "avg_logprob": -0.18863224637681159,
                "compression_ratio": 1.5736196319018405,
                "end": 41.12,
                "id": 9,
                "no_speech_prob": 0.1822509765625,
                "seek": 5644,
                "start": 38.02,
                "temperature": 0,
                "text": " of matrix multiplication and vector transformations in parallel.",
                "tokens": [
                    50883,
                    295,
                    8141,
                    27290,
                    293,
                    8062,
                    34852,
                    294,
                    8952,
                    13,
                    51058
                ]
            },
            {
                "avg_logprob": -0.18863224637681159,
                "compression_ratio": 1.5736196319018405,
                "end": 42.14,
                "id": 10,
                "no_speech_prob": 0.1822509765625,
                "seek": 5644,
                "start": 41.38,
                "temperature": 0,
                "text": " And I mean a lot.",
                "tokens": [
                    51058,
                    400,
                    286,
                    914,
                    257,
                    688,
                    13,
                    51108
                ]
            },
            {
                "avg_logprob": -0.18863224637681159,
                "compression_ratio": 1.5736196319018405,
                "end": 46.78,
                "id": 11,
                "no_speech_prob": 0.1822509765625,
                "seek": 5644,
                "start": 42.32,
                "temperature": 0,
                "text": " Modern GPUs are measured in tariff lops, or how many trillions of floating point operations",
                "tokens": [
                    51108,
                    19814,
                    18407,
                    82,
                    366,
                    12690,
                    294,
                    3112,
                    3661,
                    287,
                    3370,
                    11,
                    420,
                    577,
                    867,
                    504,
                    46279,
                    295,
                    12607,
                    935,
                    7705,
                    51326
                ]
            },
            {
                "avg_logprob": -0.18863224637681159,
                "compression_ratio": 1.5736196319018405,
                "end": 51.7,
                "id": 12,
                "no_speech_prob": 0.1822509765625,
                "seek": 5644,
                "start": 46.78,
                "temperature": 0,
                "text": " can it handle per second, unlike modern CPUs like the Intel i9, which has 24 cores.",
                "tokens": [
                    51326,
                    393,
                    309,
                    4813,
                    680,
                    1150,
                    11,
                    8343,
                    4363,
                    13199,
                    82,
                    411,
                    264,
                    19762,
                    741,
                    24,
                    11,
                    597,
                    575,
                    4022,
                    24826,
                    13,
                    51578
                ]
            },
            {
                "avg_logprob": -0.18863224637681159,
                "compression_ratio": 1.5736196319018405,
                "end": 56.44,
                "id": 13,
                "no_speech_prob": 0.1822509765625,
                "seek": 5644,
                "start": 51.92,
                "temperature": 0,
                "text": " A modern GPU like the RTX 4090 has over 16,000 cores.",
                "tokens": [
                    51578,
                    316,
                    4363,
                    18407,
                    411,
                    264,
                    44573,
                    3356,
                    7771,
                    575,
                    670,
                    3165,
                    11,
                    1360,
                    24826,
                    13,
                    51818
                ]
            },
            {
                "avg_logprob": -0.11964465725806452,
                "compression_ratio": 1.7142857142857142,
                "end": 61.46,
                "id": 14,
                "no_speech_prob": 0.173095703125,
                "seek": 8234,
                "start": 56.44,
                "temperature": 0,
                "text": " A CPU is designed to be versatile, while a GPU is designed to go really fast in parallel.",
                "tokens": [
                    50364,
                    316,
                    13199,
                    307,
                    4761,
                    281,
                    312,
                    25057,
                    11,
                    1339,
                    257,
                    18407,
                    307,
                    4761,
                    281,
                    352,
                    534,
                    2370,
                    294,
                    8952,
                    13,
                    50630
                ]
            },
            {
                "avg_logprob": -0.11964465725806452,
                "compression_ratio": 1.7142857142857142,
                "end": 66.04,
                "id": 15,
                "no_speech_prob": 0.173095703125,
                "seek": 8234,
                "start": 61.66,
                "temperature": 0,
                "text": " CUDA allows developers to tap into the GPU's power, and data scientists all around the world",
                "tokens": [
                    50630,
                    29777,
                    7509,
                    4045,
                    8849,
                    281,
                    5119,
                    666,
                    264,
                    18407,
                    311,
                    1347,
                    11,
                    293,
                    1412,
                    7708,
                    439,
                    926,
                    264,
                    1002,
                    50846
                ]
            },
            {
                "avg_logprob": -0.11964465725806452,
                "compression_ratio": 1.7142857142857142,
                "end": 69.86,
                "id": 16,
                "no_speech_prob": 0.173095703125,
                "seek": 8234,
                "start": 66.04,
                "temperature": 0,
                "text": " are using at this very moment, trying to train the most powerful machine learning models.",
                "tokens": [
                    50846,
                    366,
                    1228,
                    412,
                    341,
                    588,
                    1623,
                    11,
                    1382,
                    281,
                    3847,
                    264,
                    881,
                    4005,
                    3479,
                    2539,
                    5245,
                    13,
                    51052
                ]
            },
            {
                "avg_logprob": -0.11964465725806452,
                "compression_ratio": 1.7142857142857142,
                "end": 70.84,
                "id": 17,
                "no_speech_prob": 0.173095703125,
                "seek": 8234,
                "start": 70.12,
                "temperature": 0,
                "text": " It works like this.",
                "tokens": [
                    51052,
                    467,
                    1985,
                    411,
                    341,
                    13,
                    51102
                ]
            },
            {
                "avg_logprob": -0.11964465725806452,
                "compression_ratio": 1.7142857142857142,
                "end": 74.16,
                "id": 18,
                "no_speech_prob": 0.173095703125,
                "seek": 8234,
                "start": 71.1,
                "temperature": 0,
                "text": " You write a function called a CUDA kernel that runs on the GPU.",
                "tokens": [
                    51102,
                    509,
                    2464,
                    257,
                    2445,
                    1219,
                    257,
                    29777,
                    7509,
                    28256,
                    300,
                    6676,
                    322,
                    264,
                    18407,
                    13,
                    51272
                ]
            },
            {
                "avg_logprob": -0.11964465725806452,
                "compression_ratio": 1.7142857142857142,
                "end": 79.1,
                "id": 19,
                "no_speech_prob": 0.173095703125,
                "seek": 8234,
                "start": 74.56,
                "temperature": 0,
                "text": " You then copy some data from your main RAM over to the GPU's memory, then the CPU will",
                "tokens": [
                    51272,
                    509,
                    550,
                    5055,
                    512,
                    1412,
                    490,
                    428,
                    2135,
                    14561,
                    670,
                    281,
                    264,
                    18407,
                    311,
                    4675,
                    11,
                    550,
                    264,
                    13199,
                    486,
                    51498
                ]
            },
            {
                "avg_logprob": -0.11964465725806452,
                "compression_ratio": 1.7142857142857142,
                "end": 82.34,
                "id": 20,
                "no_speech_prob": 0.173095703125,
                "seek": 8234,
                "start": 79.1,
                "temperature": 0,
                "text": " tell the GPU to execute that function or kernel in parallel.",
                "tokens": [
                    51498,
                    980,
                    264,
                    18407,
                    281,
                    14483,
                    300,
                    2445,
                    420,
                    28256,
                    294,
                    8952,
                    13,
                    51674
                ]
            },
            {
                "avg_logprob": -0.1810844370860927,
                "compression_ratio": 1.5914285714285714,
                "end": 86.8,
                "id": 21,
                "no_speech_prob": 0.0078125,
                "seek": 11128,
                "start": 82.34,
                "temperature": 0,
                "text": " Well, the code is executed in a block, which itself organizes threads into a multidimensional",
                "tokens": [
                    50364,
                    1042,
                    11,
                    264,
                    3089,
                    307,
                    17577,
                    294,
                    257,
                    3461,
                    11,
                    597,
                    2564,
                    4645,
                    279,
                    19314,
                    666,
                    257,
                    2120,
                    327,
                    332,
                    11075,
                    50590
                ]
            },
            {
                "avg_logprob": -0.1810844370860927,
                "compression_ratio": 1.5914285714285714,
                "end": 87.08,
                "id": 22,
                "no_speech_prob": 0.0078125,
                "seek": 11128,
                "start": 86.8,
                "temperature": 0,
                "text": " grid.",
                "tokens": [
                    50590,
                    10748,
                    13,
                    50640
                ]
            },
            {
                "avg_logprob": -0.1810844370860927,
                "compression_ratio": 1.5914285714285714,
                "end": 90.6,
                "id": 23,
                "no_speech_prob": 0.0078125,
                "seek": 11128,
                "start": 87.3,
                "temperature": 0,
                "text": " Then the final result from the GPU is copied back to the main memory.",
                "tokens": [
                    50640,
                    1396,
                    264,
                    2572,
                    1874,
                    490,
                    264,
                    18407,
                    307,
                    25365,
                    646,
                    281,
                    264,
                    2135,
                    4675,
                    13,
                    50790
                ]
            },
            {
                "avg_logprob": -0.1810844370860927,
                "compression_ratio": 1.5914285714285714,
                "end": 93.94,
                "id": 24,
                "no_speech_prob": 0.0078125,
                "seek": 11128,
                "start": 90.86,
                "temperature": 0,
                "text": " A piece of cake, let's go ahead and build a CUDA application right now.",
                "tokens": [
                    50790,
                    316,
                    2522,
                    295,
                    5908,
                    11,
                    718,
                    311,
                    352,
                    2286,
                    293,
                    1322,
                    257,
                    29777,
                    7509,
                    3861,
                    558,
                    586,
                    13,
                    50964
                ]
            },
            {
                "avg_logprob": -0.1810844370860927,
                "compression_ratio": 1.5914285714285714,
                "end": 97.24,
                "id": 25,
                "no_speech_prob": 0.0078125,
                "seek": 11128,
                "start": 94.14,
                "temperature": 0,
                "text": " First you'll need an Nvidia GPU, then install the CUDA toolkit.",
                "tokens": [
                    50964,
                    2386,
                    291,
                    603,
                    643,
                    364,
                    46284,
                    18407,
                    11,
                    550,
                    3625,
                    264,
                    29777,
                    7509,
                    40167,
                    13,
                    51126
                ]
            },
            {
                "avg_logprob": -0.1810844370860927,
                "compression_ratio": 1.5914285714285714,
                "end": 102.1,
                "id": 26,
                "no_speech_prob": 0.0078125,
                "seek": 11128,
                "start": 97.54,
                "temperature": 0,
                "text": " CUDA includes device drivers, a runtime, compilers, and dev tools, but the actual code",
                "tokens": [
                    51126,
                    29777,
                    7509,
                    5974,
                    4302,
                    11590,
                    11,
                    257,
                    34474,
                    11,
                    715,
                    388,
                    433,
                    11,
                    293,
                    1905,
                    3873,
                    11,
                    457,
                    264,
                    3539,
                    3089,
                    51354
                ]
            },
            {
                "avg_logprob": -0.1810844370860927,
                "compression_ratio": 1.5914285714285714,
                "end": 103.58,
                "id": 27,
                "no_speech_prob": 0.0078125,
                "seek": 11128,
                "start": 102.1,
                "temperature": 0,
                "text": " is most often written in C++.",
                "tokens": [
                    51354,
                    307,
                    881,
                    2049,
                    3720,
                    294,
                    383,
                    25472,
                    13,
                    51458
                ]
            },
            {
                "avg_logprob": -0.1810844370860927,
                "compression_ratio": 1.5914285714285714,
                "end": 108.72,
                "id": 28,
                "no_speech_prob": 0.0078125,
                "seek": 11128,
                "start": 104.14,
                "temperature": 0,
                "text": " As I'm doing here in Visual Studio, first we use the global specifier to define a function",
                "tokens": [
                    51458,
                    1018,
                    286,
                    478,
                    884,
                    510,
                    294,
                    23187,
                    13500,
                    11,
                    700,
                    321,
                    764,
                    264,
                    4338,
                    1608,
                    9902,
                    281,
                    6964,
                    257,
                    2445,
                    51688
                ]
            },
            {
                "avg_logprob": -0.1810844370860927,
                "compression_ratio": 1.5914285714285714,
                "end": 111.28,
                "id": 29,
                "no_speech_prob": 0.0078125,
                "seek": 11128,
                "start": 108.72,
                "temperature": 0,
                "text": " or CUDA kernel that runs on the actual GPU.",
                "tokens": [
                    51688,
                    420,
                    29777,
                    7509,
                    28256,
                    300,
                    6676,
                    322,
                    264,
                    3539,
                    18407,
                    13,
                    51834
                ]
            },
            {
                "avg_logprob": -0.15558035714285715,
                "compression_ratio": 1.7064220183486238,
                "end": 114.22,
                "id": 30,
                "no_speech_prob": 0.2335205078125,
                "seek": 13906,
                "start": 111.28,
                "temperature": 0,
                "text": " U. This function adds two vectors or arrays together.",
                "tokens": [
                    50364,
                    624,
                    13,
                    639,
                    2445,
                    10860,
                    732,
                    18875,
                    420,
                    41011,
                    1214,
                    13,
                    50530
                ]
            },
            {
                "avg_logprob": -0.15558035714285715,
                "compression_ratio": 1.7064220183486238,
                "end": 118.5,
                "id": 31,
                "no_speech_prob": 0.2335205078125,
                "seek": 13906,
                "start": 114.54,
                "temperature": 0,
                "text": " It takes pointer arguments A and B, which are the two vectors to be added together, and",
                "tokens": [
                    50530,
                    467,
                    2516,
                    23918,
                    12869,
                    316,
                    293,
                    363,
                    11,
                    597,
                    366,
                    264,
                    732,
                    18875,
                    281,
                    312,
                    3869,
                    1214,
                    11,
                    293,
                    50728
                ]
            },
            {
                "avg_logprob": -0.15558035714285715,
                "compression_ratio": 1.7064220183486238,
                "end": 119.78,
                "id": 32,
                "no_speech_prob": 0.2335205078125,
                "seek": 13906,
                "start": 118.5,
                "temperature": 0,
                "text": " pointer C for the result.",
                "tokens": [
                    50728,
                    23918,
                    383,
                    337,
                    264,
                    1874,
                    13,
                    50806
                ]
            },
            {
                "avg_logprob": -0.15558035714285715,
                "compression_ratio": 1.7064220183486238,
                "end": 124.52,
                "id": 33,
                "no_speech_prob": 0.2335205078125,
                "seek": 13906,
                "start": 120,
                "temperature": 0,
                "text": " C equals A plus B, but because hypothetically we're doing billions of operations in parallel,",
                "tokens": [
                    50806,
                    383,
                    6915,
                    316,
                    1804,
                    363,
                    11,
                    457,
                    570,
                    24371,
                    22652,
                    321,
                    434,
                    884,
                    17375,
                    295,
                    7705,
                    294,
                    8952,
                    11,
                    51042
                ]
            },
            {
                "avg_logprob": -0.15558035714285715,
                "compression_ratio": 1.7064220183486238,
                "end": 128.36,
                "id": 34,
                "no_speech_prob": 0.2335205078125,
                "seek": 13906,
                "start": 124.8,
                "temperature": 0,
                "text": " we need to calculate the global index of the thread and the block that we're working",
                "tokens": [
                    51042,
                    321,
                    643,
                    281,
                    8873,
                    264,
                    4338,
                    8186,
                    295,
                    264,
                    7207,
                    293,
                    264,
                    3461,
                    300,
                    321,
                    434,
                    1364,
                    51218
                ]
            },
            {
                "avg_logprob": -0.15558035714285715,
                "compression_ratio": 1.7064220183486238,
                "end": 128.58,
                "id": 35,
                "no_speech_prob": 0.2335205078125,
                "seek": 13906,
                "start": 128.36,
                "temperature": 0,
                "text": " on.",
                "tokens": [
                    51218,
                    322,
                    13,
                    51268
                ]
            },
            {
                "avg_logprob": -0.15558035714285715,
                "compression_ratio": 1.7064220183486238,
                "end": 132.84,
                "id": 36,
                "no_speech_prob": 0.2335205078125,
                "seek": 13906,
                "start": 128.66,
                "temperature": 0,
                "text": " From there, we can use Managed, which tells CUDA this data can be accessed from both the",
                "tokens": [
                    51268,
                    3358,
                    456,
                    11,
                    321,
                    393,
                    764,
                    2458,
                    2980,
                    11,
                    597,
                    5112,
                    29777,
                    7509,
                    341,
                    1412,
                    393,
                    312,
                    34211,
                    490,
                    1293,
                    264,
                    51442
                ]
            },
            {
                "avg_logprob": -0.15558035714285715,
                "compression_ratio": 1.7064220183486238,
                "end": 134.86,
                "id": 37,
                "no_speech_prob": 0.2335205078125,
                "seek": 13906,
                "start": 132.84,
                "temperature": 0,
                "text": " host CPU and the device GPU.",
                "tokens": [
                    51442,
                    3975,
                    13199,
                    293,
                    264,
                    4302,
                    18407,
                    13,
                    51576
                ]
            },
            {
                "avg_logprob": -0.15558035714285715,
                "compression_ratio": 1.7064220183486238,
                "end": 139.06,
                "id": 38,
                "no_speech_prob": 0.2335205078125,
                "seek": 13906,
                "start": 135.26,
                "temperature": 0,
                "text": " Without the need to manually copy data between them, and now we can write a main function",
                "tokens": [
                    51576,
                    9129,
                    264,
                    643,
                    281,
                    16945,
                    5055,
                    1412,
                    1296,
                    552,
                    11,
                    293,
                    586,
                    321,
                    393,
                    2464,
                    257,
                    2135,
                    2445,
                    51754
                ]
            },
            {
                "avg_logprob": -0.09484145220588236,
                "compression_ratio": 1.6991150442477876,
                "end": 143.74,
                "id": 39,
                "no_speech_prob": 0.244873046875,
                "seek": 16670,
                "start": 139.06,
                "temperature": 0,
                "text": " for the CPU that runs the CUDA kernel. We use a for loop to initialize our arrays with data.",
                "tokens": [
                    50364,
                    337,
                    264,
                    13199,
                    300,
                    6676,
                    264,
                    29777,
                    7509,
                    28256,
                    13,
                    492,
                    764,
                    257,
                    337,
                    6367,
                    281,
                    5883,
                    1125,
                    527,
                    41011,
                    365,
                    1412,
                    13,
                    50604
                ]
            },
            {
                "avg_logprob": -0.09484145220588236,
                "compression_ratio": 1.6991150442477876,
                "end": 148.72,
                "id": 40,
                "no_speech_prob": 0.244873046875,
                "seek": 16670,
                "start": 143.92,
                "temperature": 0,
                "text": " Then from there we pass this data to the ad function to run it on the GPU. But you might be",
                "tokens": [
                    50604,
                    1396,
                    490,
                    456,
                    321,
                    1320,
                    341,
                    1412,
                    281,
                    264,
                    614,
                    2445,
                    281,
                    1190,
                    309,
                    322,
                    264,
                    18407,
                    13,
                    583,
                    291,
                    1062,
                    312,
                    50844
                ]
            },
            {
                "avg_logprob": -0.09484145220588236,
                "compression_ratio": 1.6991150442477876,
                "end": 152.98,
                "id": 41,
                "no_speech_prob": 0.244873046875,
                "seek": 16670,
                "start": 148.72,
                "temperature": 0,
                "text": " wondering what these weird triple brackets are. They allow us to configure the CUDA kernel launch",
                "tokens": [
                    50844,
                    6359,
                    437,
                    613,
                    3657,
                    15508,
                    26179,
                    366,
                    13,
                    814,
                    2089,
                    505,
                    281,
                    22162,
                    264,
                    29777,
                    7509,
                    28256,
                    4025,
                    51060
                ]
            },
            {
                "avg_logprob": -0.09484145220588236,
                "compression_ratio": 1.6991150442477876,
                "end": 157.26,
                "id": 42,
                "no_speech_prob": 0.244873046875,
                "seek": 16670,
                "start": 152.98,
                "temperature": 0,
                "text": " to control how many blocks and how many threads per block are used to run this code in parallel.",
                "tokens": [
                    51060,
                    281,
                    1969,
                    577,
                    867,
                    8474,
                    293,
                    577,
                    867,
                    19314,
                    680,
                    3461,
                    366,
                    1143,
                    281,
                    1190,
                    341,
                    3089,
                    294,
                    8952,
                    13,
                    51276
                ]
            },
            {
                "avg_logprob": -0.09484145220588236,
                "compression_ratio": 1.6991150442477876,
                "end": 162,
                "id": 43,
                "no_speech_prob": 0.244873046875,
                "seek": 16670,
                "start": 157.4,
                "temperature": 0,
                "text": " And that's crucial for optimizing multi-dimensional data structures like tensors used in deep learning.",
                "tokens": [
                    51276,
                    400,
                    300,
                    311,
                    11462,
                    337,
                    40425,
                    4825,
                    12,
                    18759,
                    1412,
                    9227,
                    411,
                    10688,
                    830,
                    1143,
                    294,
                    2452,
                    2539,
                    13,
                    51516
                ]
            },
            {
                "avg_logprob": -0.09484145220588236,
                "compression_ratio": 1.6991150442477876,
                "end": 166.7,
                "id": 44,
                "no_speech_prob": 0.244873046875,
                "seek": 16670,
                "start": 162.22,
                "temperature": 0,
                "text": " From there, CUDA device synchronize will pause the execution of this code and wait for it to",
                "tokens": [
                    51516,
                    3358,
                    456,
                    11,
                    29777,
                    7509,
                    4302,
                    19331,
                    1125,
                    486,
                    10465,
                    264,
                    15058,
                    295,
                    341,
                    3089,
                    293,
                    1699,
                    337,
                    309,
                    281,
                    51744
                ]
            },
            {
                "avg_logprob": -0.1391826923076923,
                "compression_ratio": 1.5722713864306785,
                "end": 170.68,
                "id": 45,
                "no_speech_prob": 0.0037631988525390625,
                "seek": 19245,
                "start": 166.7,
                "temperature": 0,
                "text": " complete on the GPU. When it finishes and copies the data back to the host machine,",
                "tokens": [
                    50364,
                    3566,
                    322,
                    264,
                    18407,
                    13,
                    1133,
                    309,
                    23615,
                    293,
                    14341,
                    264,
                    1412,
                    646,
                    281,
                    264,
                    3975,
                    3479,
                    11,
                    50564
                ]
            },
            {
                "avg_logprob": -0.1391826923076923,
                "compression_ratio": 1.5722713864306785,
                "end": 173.28,
                "id": 46,
                "no_speech_prob": 0.0037631988525390625,
                "seek": 19245,
                "start": 170.86,
                "temperature": 0,
                "text": " we can then use the result and print it to the standard output.",
                "tokens": [
                    50564,
                    321,
                    393,
                    550,
                    764,
                    264,
                    1874,
                    293,
                    4482,
                    309,
                    281,
                    264,
                    3832,
                    5598,
                    13,
                    50700
                ]
            },
            {
                "avg_logprob": -0.1391826923076923,
                "compression_ratio": 1.5722713864306785,
                "end": 176.94,
                "id": 47,
                "no_speech_prob": 0.0037631988525390625,
                "seek": 19245,
                "start": 173.52,
                "temperature": 0,
                "text": " Now, let's execute this code with a CUDA compiler by clicking the play button.",
                "tokens": [
                    50700,
                    823,
                    11,
                    718,
                    311,
                    14483,
                    341,
                    3089,
                    365,
                    257,
                    29777,
                    7509,
                    31958,
                    538,
                    9697,
                    264,
                    862,
                    2960,
                    13,
                    50880
                ]
            },
            {
                "avg_logprob": -0.1391826923076923,
                "compression_ratio": 1.5722713864306785,
                "end": 181.16,
                "id": 48,
                "no_speech_prob": 0.0037631988525390625,
                "seek": 19245,
                "start": 177.14,
                "temperature": 0,
                "text": " Congratulations, you just ran 256 threads and parallel on your GPU.",
                "tokens": [
                    50880,
                    9694,
                    11,
                    291,
                    445,
                    5872,
                    38882,
                    19314,
                    293,
                    8952,
                    322,
                    428,
                    18407,
                    13,
                    51096
                ]
            },
            {
                "avg_logprob": -0.1391826923076923,
                "compression_ratio": 1.5722713864306785,
                "end": 185.08,
                "id": 49,
                "no_speech_prob": 0.0037631988525390625,
                "seek": 19245,
                "start": 181.48,
                "temperature": 0,
                "text": " But if you want to go beyond, Nvidia's GTC conference is coming up in a few weeks.",
                "tokens": [
                    51096,
                    583,
                    498,
                    291,
                    528,
                    281,
                    352,
                    4399,
                    11,
                    46284,
                    311,
                    17530,
                    34,
                    7586,
                    307,
                    1348,
                    493,
                    294,
                    257,
                    1326,
                    3259,
                    13,
                    51288
                ]
            },
            {
                "avg_logprob": -0.1391826923076923,
                "compression_ratio": 1.5722713864306785,
                "end": 189.78,
                "id": 50,
                "no_speech_prob": 0.0037631988525390625,
                "seek": 19245,
                "start": 185.34,
                "temperature": 0,
                "text": " It's free to attend virtually if featuring talks about building massive parallel systems with CUDA.",
                "tokens": [
                    51288,
                    467,
                    311,
                    1737,
                    281,
                    6888,
                    14103,
                    498,
                    19742,
                    6686,
                    466,
                    2390,
                    5994,
                    8952,
                    3652,
                    365,
                    29777,
                    7509,
                    13,
                    51520
                ]
            },
            {
                "avg_logprob": -0.1391826923076923,
                "compression_ratio": 1.5722713864306785,
                "end": 192.1,
                "id": 51,
                "no_speech_prob": 0.0037631988525390625,
                "seek": 19245,
                "start": 190,
                "temperature": 0,
                "text": " Thanks for watching and I will see you in the next one.",
                "tokens": [
                    51520,
                    2561,
                    337,
                    1976,
                    293,
                    286,
                    486,
                    536,
                    291,
                    294,
                    264,
                    958,
                    472,
                    13,
                    51648
                ]
            }
        ],
        "transcription": "CUDA, a parallel computing platform that allows you to use your GPU for more than just playing video games. Compute Unified Device Architecture was developed by Nvidia in 2007 based on the prior work of Ian Buck and John Nichols. Since then, CUDA has revolutionized the world by allowing humans to compute large blocks of data in parallel, which is unlock the true potential of the deep neural networks behind artificial intelligence. The graphics processing unit, or GPU, is historically used for what the name implies. 2-compute graphics. When you play a game in 1080p at 60fps, you've got over 2 million pixels on the screen that may need to be recalculated after every frame, which requires hardware that can do a lot of matrix multiplication and vector transformations in parallel. And I mean a lot. Modern GPUs are measured in tariff lops, or how many trillions of floating point operations can it handle per second, unlike modern CPUs like the Intel i9, which has 24 cores. A modern GPU like the RTX 4090 has over 16,000 cores. A CPU is designed to be versatile, while a GPU is designed to go really fast in parallel. CUDA allows developers to tap into the GPU's power, and data scientists all around the world are using at this very moment, trying to train the most powerful machine learning models. It works like this. You write a function called a CUDA kernel that runs on the GPU. You then copy some data from your main RAM over to the GPU's memory, then the CPU will tell the GPU to execute that function or kernel in parallel. Well, the code is executed in a block, which itself organizes threads into a multidimensional grid. Then the final result from the GPU is copied back to the main memory. A piece of cake, let's go ahead and build a CUDA application right now. First you'll need an Nvidia GPU, then install the CUDA toolkit. CUDA includes device drivers, a runtime, compilers, and dev tools, but the actual code is most often written in C++. As I'm doing here in Visual Studio, first we use the global specifier to define a function or CUDA kernel that runs on the actual GPU. U. This function adds two vectors or arrays together. It takes pointer arguments A and B, which are the two vectors to be added together, and pointer C for the result. C equals A plus B, but because hypothetically we're doing billions of operations in parallel, we need to calculate the global index of the thread and the block that we're working on. From there, we can use Managed, which tells CUDA this data can be accessed from both the host CPU and the device GPU. Without the need to manually copy data between them, and now we can write a main function for the CPU that runs the CUDA kernel. We use a for loop to initialize our arrays with data. Then from there we pass this data to the ad function to run it on the GPU. But you might be wondering what these weird triple brackets are. They allow us to configure the CUDA kernel launch to control how many blocks and how many threads per block are used to run this code in parallel. And that's crucial for optimizing multi-dimensional data structures like tensors used in deep learning. From there, CUDA device synchronize will pause the execution of this code and wait for it to complete on the GPU. When it finishes and copies the data back to the host machine, we can then use the result and print it to the standard output. Now, let's execute this code with a CUDA compiler by clicking the play button. Congratulations, you just ran 256 threads and parallel on your GPU. But if you want to go beyond, Nvidia's GTC conference is coming up in a few weeks. It's free to attend virtually if featuring talks about building massive parallel systems with CUDA. Thanks for watching and I will see you in the next one.",
        "translation": null,
        "word_timestamps": [
            {
                "end": 0.62,
                "start": 0,
                "word": " CUDA,"
            },
            {
                "end": 1.08,
                "start": 0.92,
                "word": " a"
            },
            {
                "end": 1.42,
                "start": 1.08,
                "word": " parallel"
            },
            {
                "end": 1.86,
                "start": 1.42,
                "word": " computing"
            },
            {
                "end": 2.34,
                "start": 1.86,
                "word": " platform"
            },
            {
                "end": 2.72,
                "start": 2.34,
                "word": " that"
            },
            {
                "end": 3,
                "start": 2.72,
                "word": " allows"
            },
            {
                "end": 3.22,
                "start": 3,
                "word": " you"
            },
            {
                "end": 3.36,
                "start": 3.22,
                "word": " to"
            },
            {
                "end": 3.58,
                "start": 3.36,
                "word": " use"
            },
            {
                "end": 3.74,
                "start": 3.58,
                "word": " your"
            },
            {
                "end": 4.12,
                "start": 3.74,
                "word": " GPU"
            },
            {
                "end": 4.68,
                "start": 4.12,
                "word": " for"
            },
            {
                "end": 4.92,
                "start": 4.68,
                "word": " more"
            },
            {
                "end": 5.06,
                "start": 4.92,
                "word": " than"
            },
            {
                "end": 5.24,
                "start": 5.06,
                "word": " just"
            },
            {
                "end": 5.48,
                "start": 5.24,
                "word": " playing"
            },
            {
                "end": 5.82,
                "start": 5.48,
                "word": " video"
            },
            {
                "end": 6.28,
                "start": 5.82,
                "word": " games."
            },
            {
                "end": 6.82,
                "start": 6.4,
                "word": " Compute"
            },
            {
                "end": 7.22,
                "start": 6.82,
                "word": " Unified"
            },
            {
                "end": 7.64,
                "start": 7.22,
                "word": " Device"
            },
            {
                "end": 8.2,
                "start": 7.64,
                "word": " Architecture"
            },
            {
                "end": 8.56,
                "start": 8.2,
                "word": " was"
            },
            {
                "end": 8.9,
                "start": 8.56,
                "word": " developed"
            },
            {
                "end": 9.14,
                "start": 8.9,
                "word": " by"
            },
            {
                "end": 9.5,
                "start": 9.14,
                "word": " Nvidia"
            },
            {
                "end": 9.84,
                "start": 9.5,
                "word": " in"
            },
            {
                "end": 10.58,
                "start": 9.84,
                "word": " 2007"
            },
            {
                "end": 10.98,
                "start": 10.58,
                "word": " based"
            },
            {
                "end": 11.14,
                "start": 10.98,
                "word": " on"
            },
            {
                "end": 11.22,
                "start": 11.14,
                "word": " the"
            },
            {
                "end": 11.46,
                "start": 11.22,
                "word": " prior"
            },
            {
                "end": 11.76,
                "start": 11.46,
                "word": " work"
            },
            {
                "end": 11.92,
                "start": 11.76,
                "word": " of"
            },
            {
                "end": 12.14,
                "start": 11.92,
                "word": " Ian"
            },
            {
                "end": 12.4,
                "start": 12.14,
                "word": " Buck"
            },
            {
                "end": 12.66,
                "start": 12.4,
                "word": " and"
            },
            {
                "end": 12.88,
                "start": 12.66,
                "word": " John"
            },
            {
                "end": 13.32,
                "start": 12.88,
                "word": " Nichols."
            },
            {
                "end": 13.72,
                "start": 13.6,
                "word": " Since"
            },
            {
                "end": 14.06,
                "start": 13.72,
                "word": " then,"
            },
            {
                "end": 14.4,
                "start": 14.26,
                "word": " CUDA"
            },
            {
                "end": 14.54,
                "start": 14.4,
                "word": " has"
            },
            {
                "end": 15.22,
                "start": 14.54,
                "word": " revolutionized"
            },
            {
                "end": 15.4,
                "start": 15.22,
                "word": " the"
            },
            {
                "end": 15.64,
                "start": 15.4,
                "word": " world"
            },
            {
                "end": 15.92,
                "start": 15.64,
                "word": " by"
            },
            {
                "end": 16.24,
                "start": 15.92,
                "word": " allowing"
            },
            {
                "end": 16.58,
                "start": 16.24,
                "word": " humans"
            },
            {
                "end": 16.8,
                "start": 16.58,
                "word": " to"
            },
            {
                "end": 17.08,
                "start": 16.8,
                "word": " compute"
            },
            {
                "end": 17.44,
                "start": 17.08,
                "word": " large"
            },
            {
                "end": 17.72,
                "start": 17.44,
                "word": " blocks"
            },
            {
                "end": 17.92,
                "start": 17.72,
                "word": " of"
            },
            {
                "end": 18.12,
                "start": 17.92,
                "word": " data"
            },
            {
                "end": 18.36,
                "start": 18.12,
                "word": " in"
            },
            {
                "end": 18.72,
                "start": 18.36,
                "word": " parallel,"
            },
            {
                "end": 19.16,
                "start": 18.98,
                "word": " which"
            },
            {
                "end": 19.3,
                "start": 19.16,
                "word": " is"
            },
            {
                "end": 19.62,
                "start": 19.3,
                "word": " unlock"
            },
            {
                "end": 19.86,
                "start": 19.62,
                "word": " the"
            },
            {
                "end": 20.02,
                "start": 19.86,
                "word": " true"
            },
            {
                "end": 20.44,
                "start": 20.02,
                "word": " potential"
            },
            {
                "end": 20.72,
                "start": 20.44,
                "word": " of"
            },
            {
                "end": 20.86,
                "start": 20.72,
                "word": " the"
            },
            {
                "end": 21.08,
                "start": 20.86,
                "word": " deep"
            },
            {
                "end": 21.26,
                "start": 21.08,
                "word": " neural"
            },
            {
                "end": 21.68,
                "start": 21.26,
                "word": " networks"
            },
            {
                "end": 22.04,
                "start": 21.68,
                "word": " behind"
            },
            {
                "end": 22.58,
                "start": 22.04,
                "word": " artificial"
            },
            {
                "end": 23.18,
                "start": 22.58,
                "word": " intelligence."
            },
            {
                "end": 23.44,
                "start": 23.36,
                "word": " The"
            },
            {
                "end": 23.74,
                "start": 23.44,
                "word": " graphics"
            },
            {
                "end": 24.32,
                "start": 23.74,
                "word": " processing"
            },
            {
                "end": 24.7,
                "start": 24.32,
                "word": " unit,"
            },
            {
                "end": 24.88,
                "start": 24.7,
                "word": " or"
            },
            {
                "end": 25.28,
                "start": 24.88,
                "word": " GPU,"
            },
            {
                "end": 25.74,
                "start": 25.68,
                "word": " is"
            },
            {
                "end": 26.18,
                "start": 25.74,
                "word": " historically"
            },
            {
                "end": 26.62,
                "start": 26.18,
                "word": " used"
            },
            {
                "end": 26.8,
                "start": 26.62,
                "word": " for"
            },
            {
                "end": 26.98,
                "start": 26.8,
                "word": " what"
            },
            {
                "end": 27.08,
                "start": 26.98,
                "word": " the"
            },
            {
                "end": 27.22,
                "start": 27.08,
                "word": " name"
            },
            {
                "end": 27.66,
                "start": 27.22,
                "word": " implies."
            },
            {
                "end": 28.02,
                "start": 27.66,
                "word": " 2"
            },
            {
                "end": 28.36,
                "start": 28.02,
                "word": "-compute"
            },
            {
                "end": 28.78,
                "start": 28.36,
                "word": " graphics."
            },
            {
                "end": 29.2,
                "start": 29.12,
                "word": " When"
            },
            {
                "end": 29.3,
                "start": 29.2,
                "word": " you"
            },
            {
                "end": 29.5,
                "start": 29.3,
                "word": " play"
            },
            {
                "end": 29.62,
                "start": 29.5,
                "word": " a"
            },
            {
                "end": 29.76,
                "start": 29.62,
                "word": " game"
            },
            {
                "end": 29.88,
                "start": 29.76,
                "word": " in"
            },
            {
                "end": 30.52,
                "start": 29.88,
                "word": " 1080p"
            },
            {
                "end": 30.74,
                "start": 30.52,
                "word": " at"
            },
            {
                "end": 31.62,
                "start": 30.74,
                "word": " 60fps,"
            },
            {
                "end": 32.02,
                "start": 31.9,
                "word": " you've"
            },
            {
                "end": 32.1,
                "start": 32.02,
                "word": " got"
            },
            {
                "end": 32.36,
                "start": 32.1,
                "word": " over"
            },
            {
                "end": 32.58,
                "start": 32.36,
                "word": " 2"
            },
            {
                "end": 32.78,
                "start": 32.58,
                "word": " million"
            },
            {
                "end": 33.1,
                "start": 32.78,
                "word": " pixels"
            },
            {
                "end": 33.3,
                "start": 33.1,
                "word": " on"
            },
            {
                "end": 33.42,
                "start": 33.3,
                "word": " the"
            },
            {
                "end": 33.72,
                "start": 33.42,
                "word": " screen"
            },
            {
                "end": 34.06,
                "start": 33.72,
                "word": " that"
            },
            {
                "end": 34.26,
                "start": 34.06,
                "word": " may"
            },
            {
                "end": 34.42,
                "start": 34.26,
                "word": " need"
            },
            {
                "end": 34.48,
                "start": 34.42,
                "word": " to"
            },
            {
                "end": 34.6,
                "start": 34.48,
                "word": " be"
            },
            {
                "end": 35.26,
                "start": 34.6,
                "word": " recalculated"
            },
            {
                "end": 35.54,
                "start": 35.26,
                "word": " after"
            },
            {
                "end": 35.8,
                "start": 35.54,
                "word": " every"
            },
            {
                "end": 36.08,
                "start": 35.8,
                "word": " frame,"
            },
            {
                "end": 36.3,
                "start": 36.18,
                "word": " which"
            },
            {
                "end": 36.56,
                "start": 36.3,
                "word": " requires"
            },
            {
                "end": 37.08,
                "start": 36.56,
                "word": " hardware"
            },
            {
                "end": 37.32,
                "start": 37.08,
                "word": " that"
            },
            {
                "end": 37.48,
                "start": 37.32,
                "word": " can"
            },
            {
                "end": 37.62,
                "start": 37.48,
                "word": " do"
            },
            {
                "end": 37.78,
                "start": 37.62,
                "word": " a"
            },
            {
                "end": 38.02,
                "start": 37.78,
                "word": " lot"
            },
            {
                "end": 38.18,
                "start": 38.02,
                "word": " of"
            },
            {
                "end": 38.5,
                "start": 38.18,
                "word": " matrix"
            },
            {
                "end": 39.04,
                "start": 38.5,
                "word": " multiplication"
            },
            {
                "end": 39.56,
                "start": 39.04,
                "word": " and"
            },
            {
                "end": 39.8,
                "start": 39.56,
                "word": " vector"
            },
            {
                "end": 40.38,
                "start": 39.8,
                "word": " transformations"
            },
            {
                "end": 40.78,
                "start": 40.38,
                "word": " in"
            },
            {
                "end": 41.12,
                "start": 40.78,
                "word": " parallel."
            },
            {
                "end": 41.52,
                "start": 41.38,
                "word": " And"
            },
            {
                "end": 41.66,
                "start": 41.52,
                "word": " I"
            },
            {
                "end": 41.82,
                "start": 41.66,
                "word": " mean"
            },
            {
                "end": 41.94,
                "start": 41.82,
                "word": " a"
            },
            {
                "end": 42.14,
                "start": 41.94,
                "word": " lot."
            },
            {
                "end": 42.5,
                "start": 42.32,
                "word": " Modern"
            },
            {
                "end": 43.18,
                "start": 42.5,
                "word": " GPUs"
            },
            {
                "end": 43.26,
                "start": 43.18,
                "word": " are"
            },
            {
                "end": 43.56,
                "start": 43.26,
                "word": " measured"
            },
            {
                "end": 43.72,
                "start": 43.56,
                "word": " in"
            },
            {
                "end": 44.06,
                "start": 43.72,
                "word": " tariff"
            },
            {
                "end": 44.36,
                "start": 44.06,
                "word": " lops,"
            },
            {
                "end": 44.62,
                "start": 44.54,
                "word": " or"
            },
            {
                "end": 44.82,
                "start": 44.62,
                "word": " how"
            },
            {
                "end": 45.04,
                "start": 44.82,
                "word": " many"
            },
            {
                "end": 45.48,
                "start": 45.04,
                "word": " trillions"
            },
            {
                "end": 45.7,
                "start": 45.48,
                "word": " of"
            },
            {
                "end": 45.92,
                "start": 45.7,
                "word": " floating"
            },
            {
                "end": 46.18,
                "start": 45.92,
                "word": " point"
            },
            {
                "end": 46.78,
                "start": 46.18,
                "word": " operations"
            },
            {
                "end": 47.04,
                "start": 46.78,
                "word": " can"
            },
            {
                "end": 47.16,
                "start": 47.04,
                "word": " it"
            },
            {
                "end": 47.44,
                "start": 47.16,
                "word": " handle"
            },
            {
                "end": 47.64,
                "start": 47.44,
                "word": " per"
            },
            {
                "end": 48,
                "start": 47.64,
                "word": " second,"
            },
            {
                "end": 48.32,
                "start": 48.14,
                "word": " unlike"
            },
            {
                "end": 48.64,
                "start": 48.32,
                "word": " modern"
            },
            {
                "end": 49.42,
                "start": 48.64,
                "word": " CPUs"
            },
            {
                "end": 49.56,
                "start": 49.42,
                "word": " like"
            },
            {
                "end": 49.74,
                "start": 49.56,
                "word": " the"
            },
            {
                "end": 49.98,
                "start": 49.74,
                "word": " Intel"
            },
            {
                "end": 50.46,
                "start": 49.98,
                "word": " i9,"
            },
            {
                "end": 50.78,
                "start": 50.68,
                "word": " which"
            },
            {
                "end": 50.9,
                "start": 50.78,
                "word": " has"
            },
            {
                "end": 51.34,
                "start": 50.9,
                "word": " 24"
            },
            {
                "end": 51.7,
                "start": 51.34,
                "word": " cores."
            },
            {
                "end": 51.98,
                "start": 51.92,
                "word": " A"
            },
            {
                "end": 52.24,
                "start": 51.98,
                "word": " modern"
            },
            {
                "end": 52.72,
                "start": 52.24,
                "word": " GPU"
            },
            {
                "end": 53.1,
                "start": 52.72,
                "word": " like"
            },
            {
                "end": 53.28,
                "start": 53.1,
                "word": " the"
            },
            {
                "end": 53.56,
                "start": 53.28,
                "word": " RTX"
            },
            {
                "end": 54.48,
                "start": 53.56,
                "word": " 4090"
            },
            {
                "end": 54.82,
                "start": 54.48,
                "word": " has"
            },
            {
                "end": 55.14,
                "start": 54.82,
                "word": " over"
            },
            {
                "end": 55.56,
                "start": 55.14,
                "word": " 16"
            },
            {
                "end": 56.14,
                "start": 55.56,
                "word": ",000"
            },
            {
                "end": 56.44,
                "start": 56.14,
                "word": " cores."
            },
            {
                "end": 56.84,
                "start": 56.44,
                "word": " A"
            },
            {
                "end": 57.2,
                "start": 56.84,
                "word": " CPU"
            },
            {
                "end": 57.46,
                "start": 57.2,
                "word": " is"
            },
            {
                "end": 57.7,
                "start": 57.46,
                "word": " designed"
            },
            {
                "end": 57.88,
                "start": 57.7,
                "word": " to"
            },
            {
                "end": 57.98,
                "start": 57.88,
                "word": " be"
            },
            {
                "end": 58.4,
                "start": 57.98,
                "word": " versatile,"
            },
            {
                "end": 58.78,
                "start": 58.66,
                "word": " while"
            },
            {
                "end": 58.94,
                "start": 58.78,
                "word": " a"
            },
            {
                "end": 59.22,
                "start": 58.94,
                "word": " GPU"
            },
            {
                "end": 59.66,
                "start": 59.22,
                "word": " is"
            },
            {
                "end": 59.92,
                "start": 59.66,
                "word": " designed"
            },
            {
                "end": 60.1,
                "start": 59.92,
                "word": " to"
            },
            {
                "end": 60.22,
                "start": 60.1,
                "word": " go"
            },
            {
                "end": 60.44,
                "start": 60.22,
                "word": " really"
            },
            {
                "end": 60.84,
                "start": 60.44,
                "word": " fast"
            },
            {
                "end": 61.12,
                "start": 60.84,
                "word": " in"
            },
            {
                "end": 61.46,
                "start": 61.12,
                "word": " parallel."
            },
            {
                "end": 61.86,
                "start": 61.66,
                "word": " CUDA"
            },
            {
                "end": 62.12,
                "start": 61.86,
                "word": " allows"
            },
            {
                "end": 62.66,
                "start": 62.12,
                "word": " developers"
            },
            {
                "end": 62.88,
                "start": 62.66,
                "word": " to"
            },
            {
                "end": 63.2,
                "start": 62.88,
                "word": " tap"
            },
            {
                "end": 63.4,
                "start": 63.2,
                "word": " into"
            },
            {
                "end": 63.52,
                "start": 63.4,
                "word": " the"
            },
            {
                "end": 64.04,
                "start": 63.52,
                "word": " GPU's"
            },
            {
                "end": 64.3,
                "start": 64.04,
                "word": " power,"
            },
            {
                "end": 64.58,
                "start": 64.5,
                "word": " and"
            },
            {
                "end": 64.8,
                "start": 64.58,
                "word": " data"
            },
            {
                "end": 65.18,
                "start": 64.8,
                "word": " scientists"
            },
            {
                "end": 65.5,
                "start": 65.18,
                "word": " all"
            },
            {
                "end": 65.68,
                "start": 65.5,
                "word": " around"
            },
            {
                "end": 65.82,
                "start": 65.68,
                "word": " the"
            },
            {
                "end": 66.04,
                "start": 65.82,
                "word": " world"
            },
            {
                "end": 66.24,
                "start": 66.04,
                "word": " are"
            },
            {
                "end": 66.52,
                "start": 66.24,
                "word": " using"
            },
            {
                "end": 66.7,
                "start": 66.52,
                "word": " at"
            },
            {
                "end": 66.82,
                "start": 66.7,
                "word": " this"
            },
            {
                "end": 67.1,
                "start": 66.82,
                "word": " very"
            },
            {
                "end": 67.46,
                "start": 67.1,
                "word": " moment,"
            },
            {
                "end": 67.76,
                "start": 67.6,
                "word": " trying"
            },
            {
                "end": 67.98,
                "start": 67.76,
                "word": " to"
            },
            {
                "end": 68.26,
                "start": 67.98,
                "word": " train"
            },
            {
                "end": 68.36,
                "start": 68.26,
                "word": " the"
            },
            {
                "end": 68.52,
                "start": 68.36,
                "word": " most"
            },
            {
                "end": 68.88,
                "start": 68.52,
                "word": " powerful"
            },
            {
                "end": 69.18,
                "start": 68.88,
                "word": " machine"
            },
            {
                "end": 69.42,
                "start": 69.18,
                "word": " learning"
            },
            {
                "end": 69.86,
                "start": 69.42,
                "word": " models."
            },
            {
                "end": 70.18,
                "start": 70.12,
                "word": " It"
            },
            {
                "end": 70.38,
                "start": 70.18,
                "word": " works"
            },
            {
                "end": 70.6,
                "start": 70.38,
                "word": " like"
            },
            {
                "end": 70.84,
                "start": 70.6,
                "word": " this."
            },
            {
                "end": 71.22,
                "start": 71.1,
                "word": " You"
            },
            {
                "end": 71.32,
                "start": 71.22,
                "word": " write"
            },
            {
                "end": 71.46,
                "start": 71.32,
                "word": " a"
            },
            {
                "end": 71.78,
                "start": 71.46,
                "word": " function"
            },
            {
                "end": 72.12,
                "start": 71.78,
                "word": " called"
            },
            {
                "end": 72.3,
                "start": 72.12,
                "word": " a"
            },
            {
                "end": 72.6,
                "start": 72.3,
                "word": " CUDA"
            },
            {
                "end": 72.92,
                "start": 72.6,
                "word": " kernel"
            },
            {
                "end": 73.26,
                "start": 72.92,
                "word": " that"
            },
            {
                "end": 73.58,
                "start": 73.26,
                "word": " runs"
            },
            {
                "end": 73.74,
                "start": 73.58,
                "word": " on"
            },
            {
                "end": 73.84,
                "start": 73.74,
                "word": " the"
            },
            {
                "end": 74.16,
                "start": 73.84,
                "word": " GPU."
            },
            {
                "end": 74.62,
                "start": 74.56,
                "word": " You"
            },
            {
                "end": 74.76,
                "start": 74.62,
                "word": " then"
            },
            {
                "end": 75.04,
                "start": 74.76,
                "word": " copy"
            },
            {
                "end": 75.28,
                "start": 75.04,
                "word": " some"
            },
            {
                "end": 75.52,
                "start": 75.28,
                "word": " data"
            },
            {
                "end": 75.76,
                "start": 75.52,
                "word": " from"
            },
            {
                "end": 75.92,
                "start": 75.76,
                "word": " your"
            },
            {
                "end": 76.2,
                "start": 75.92,
                "word": " main"
            },
            {
                "end": 76.44,
                "start": 76.2,
                "word": " RAM"
            },
            {
                "end": 76.82,
                "start": 76.44,
                "word": " over"
            },
            {
                "end": 76.98,
                "start": 76.82,
                "word": " to"
            },
            {
                "end": 77.06,
                "start": 76.98,
                "word": " the"
            },
            {
                "end": 77.64,
                "start": 77.06,
                "word": " GPU's"
            },
            {
                "end": 77.88,
                "start": 77.64,
                "word": " memory,"
            },
            {
                "end": 78.26,
                "start": 78.12,
                "word": " then"
            },
            {
                "end": 78.4,
                "start": 78.26,
                "word": " the"
            },
            {
                "end": 78.8,
                "start": 78.4,
                "word": " CPU"
            },
            {
                "end": 79.1,
                "start": 78.8,
                "word": " will"
            },
            {
                "end": 79.24,
                "start": 79.1,
                "word": " tell"
            },
            {
                "end": 79.38,
                "start": 79.24,
                "word": " the"
            },
            {
                "end": 79.68,
                "start": 79.38,
                "word": " GPU"
            },
            {
                "end": 80.08,
                "start": 79.68,
                "word": " to"
            },
            {
                "end": 80.54,
                "start": 80.08,
                "word": " execute"
            },
            {
                "end": 80.78,
                "start": 80.54,
                "word": " that"
            },
            {
                "end": 81.18,
                "start": 80.78,
                "word": " function"
            },
            {
                "end": 81.44,
                "start": 81.18,
                "word": " or"
            },
            {
                "end": 81.76,
                "start": 81.44,
                "word": " kernel"
            },
            {
                "end": 82,
                "start": 81.76,
                "word": " in"
            },
            {
                "end": 82.34,
                "start": 82,
                "word": " parallel."
            },
            {
                "end": 82.46,
                "start": 82.34,
                "word": " Well,"
            },
            {
                "end": 82.66,
                "start": 82.64,
                "word": " the"
            },
            {
                "end": 82.84,
                "start": 82.66,
                "word": " code"
            },
            {
                "end": 83,
                "start": 82.84,
                "word": " is"
            },
            {
                "end": 83.38,
                "start": 83,
                "word": " executed"
            },
            {
                "end": 83.64,
                "start": 83.38,
                "word": " in"
            },
            {
                "end": 83.74,
                "start": 83.64,
                "word": " a"
            },
            {
                "end": 84,
                "start": 83.74,
                "word": " block,"
            },
            {
                "end": 84.4,
                "start": 84.22,
                "word": " which"
            },
            {
                "end": 84.68,
                "start": 84.4,
                "word": " itself"
            },
            {
                "end": 85.28,
                "start": 84.68,
                "word": " organizes"
            },
            {
                "end": 85.56,
                "start": 85.28,
                "word": " threads"
            },
            {
                "end": 85.92,
                "start": 85.56,
                "word": " into"
            },
            {
                "end": 86.08,
                "start": 85.92,
                "word": " a"
            },
            {
                "end": 86.8,
                "start": 86.08,
                "word": " multidimensional"
            },
            {
                "end": 87.08,
                "start": 86.8,
                "word": " grid."
            },
            {
                "end": 87.5,
                "start": 87.3,
                "word": " Then"
            },
            {
                "end": 87.64,
                "start": 87.5,
                "word": " the"
            },
            {
                "end": 87.9,
                "start": 87.64,
                "word": " final"
            },
            {
                "end": 88.16,
                "start": 87.9,
                "word": " result"
            },
            {
                "end": 88.38,
                "start": 88.16,
                "word": " from"
            },
            {
                "end": 88.5,
                "start": 88.38,
                "word": " the"
            },
            {
                "end": 88.84,
                "start": 88.5,
                "word": " GPU"
            },
            {
                "end": 89.28,
                "start": 88.84,
                "word": " is"
            },
            {
                "end": 89.54,
                "start": 89.28,
                "word": " copied"
            },
            {
                "end": 89.82,
                "start": 89.54,
                "word": " back"
            },
            {
                "end": 90.04,
                "start": 89.82,
                "word": " to"
            },
            {
                "end": 90.12,
                "start": 90.04,
                "word": " the"
            },
            {
                "end": 90.28,
                "start": 90.12,
                "word": " main"
            },
            {
                "end": 90.6,
                "start": 90.28,
                "word": " memory."
            },
            {
                "end": 90.9,
                "start": 90.86,
                "word": " A"
            },
            {
                "end": 91.06,
                "start": 90.9,
                "word": " piece"
            },
            {
                "end": 91.22,
                "start": 91.06,
                "word": " of"
            },
            {
                "end": 91.4,
                "start": 91.22,
                "word": " cake,"
            },
            {
                "end": 91.88,
                "start": 91.58,
                "word": " let's"
            },
            {
                "end": 91.98,
                "start": 91.88,
                "word": " go"
            },
            {
                "end": 92.12,
                "start": 91.98,
                "word": " ahead"
            },
            {
                "end": 92.26,
                "start": 92.12,
                "word": " and"
            },
            {
                "end": 92.42,
                "start": 92.26,
                "word": " build"
            },
            {
                "end": 92.68,
                "start": 92.42,
                "word": " a"
            },
            {
                "end": 92.88,
                "start": 92.68,
                "word": " CUDA"
            },
            {
                "end": 93.36,
                "start": 92.88,
                "word": " application"
            },
            {
                "end": 93.7,
                "start": 93.36,
                "word": " right"
            },
            {
                "end": 93.94,
                "start": 93.7,
                "word": " now."
            },
            {
                "end": 94.26,
                "start": 94.14,
                "word": " First"
            },
            {
                "end": 94.46,
                "start": 94.26,
                "word": " you'll"
            },
            {
                "end": 94.58,
                "start": 94.46,
                "word": " need"
            },
            {
                "end": 94.74,
                "start": 94.58,
                "word": " an"
            },
            {
                "end": 95,
                "start": 94.74,
                "word": " Nvidia"
            },
            {
                "end": 95.6,
                "start": 95,
                "word": " GPU,"
            },
            {
                "end": 96.1,
                "start": 95.9,
                "word": " then"
            },
            {
                "end": 96.42,
                "start": 96.1,
                "word": " install"
            },
            {
                "end": 96.62,
                "start": 96.42,
                "word": " the"
            },
            {
                "end": 96.92,
                "start": 96.62,
                "word": " CUDA"
            },
            {
                "end": 97.24,
                "start": 96.92,
                "word": " toolkit."
            },
            {
                "end": 97.76,
                "start": 97.54,
                "word": " CUDA"
            },
            {
                "end": 98.06,
                "start": 97.76,
                "word": " includes"
            },
            {
                "end": 98.48,
                "start": 98.06,
                "word": " device"
            },
            {
                "end": 98.94,
                "start": 98.48,
                "word": " drivers,"
            },
            {
                "end": 99.2,
                "start": 99.16,
                "word": " a"
            },
            {
                "end": 99.52,
                "start": 99.2,
                "word": " runtime,"
            },
            {
                "end": 100.44,
                "start": 99.84,
                "word": " compilers,"
            },
            {
                "end": 100.62,
                "start": 100.58,
                "word": " and"
            },
            {
                "end": 100.76,
                "start": 100.62,
                "word": " dev"
            },
            {
                "end": 101.12,
                "start": 100.76,
                "word": " tools,"
            },
            {
                "end": 101.38,
                "start": 101.34,
                "word": " but"
            },
            {
                "end": 101.52,
                "start": 101.38,
                "word": " the"
            },
            {
                "end": 101.84,
                "start": 101.52,
                "word": " actual"
            },
            {
                "end": 102.1,
                "start": 101.84,
                "word": " code"
            },
            {
                "end": 102.24,
                "start": 102.1,
                "word": " is"
            },
            {
                "end": 102.38,
                "start": 102.24,
                "word": " most"
            },
            {
                "end": 102.78,
                "start": 102.38,
                "word": " often"
            },
            {
                "end": 103.02,
                "start": 102.78,
                "word": " written"
            },
            {
                "end": 103.18,
                "start": 103.02,
                "word": " in"
            },
            {
                "end": 103.58,
                "start": 103.18,
                "word": " C++."
            },
            {
                "end": 104.24,
                "start": 104.14,
                "word": " As"
            },
            {
                "end": 104.46,
                "start": 104.24,
                "word": " I'm"
            },
            {
                "end": 104.6,
                "start": 104.46,
                "word": " doing"
            },
            {
                "end": 104.88,
                "start": 104.6,
                "word": " here"
            },
            {
                "end": 105.14,
                "start": 104.88,
                "word": " in"
            },
            {
                "end": 105.42,
                "start": 105.14,
                "word": " Visual"
            },
            {
                "end": 105.82,
                "start": 105.42,
                "word": " Studio,"
            },
            {
                "end": 106.24,
                "start": 106.06,
                "word": " first"
            },
            {
                "end": 106.5,
                "start": 106.24,
                "word": " we"
            },
            {
                "end": 106.66,
                "start": 106.5,
                "word": " use"
            },
            {
                "end": 106.78,
                "start": 106.66,
                "word": " the"
            },
            {
                "end": 106.98,
                "start": 106.78,
                "word": " global"
            },
            {
                "end": 107.66,
                "start": 106.98,
                "word": " specifier"
            },
            {
                "end": 107.9,
                "start": 107.66,
                "word": " to"
            },
            {
                "end": 108.18,
                "start": 107.9,
                "word": " define"
            },
            {
                "end": 108.38,
                "start": 108.18,
                "word": " a"
            },
            {
                "end": 108.72,
                "start": 108.38,
                "word": " function"
            },
            {
                "end": 109,
                "start": 108.72,
                "word": " or"
            },
            {
                "end": 109.32,
                "start": 109,
                "word": " CUDA"
            },
            {
                "end": 109.6,
                "start": 109.32,
                "word": " kernel"
            },
            {
                "end": 109.92,
                "start": 109.6,
                "word": " that"
            },
            {
                "end": 110.2,
                "start": 109.92,
                "word": " runs"
            },
            {
                "end": 110.4,
                "start": 110.2,
                "word": " on"
            },
            {
                "end": 110.52,
                "start": 110.4,
                "word": " the"
            },
            {
                "end": 110.8,
                "start": 110.52,
                "word": " actual"
            },
            {
                "end": 111.28,
                "start": 110.8,
                "word": " GPU."
            },
            {
                "end": 111.42,
                "start": 111.28,
                "word": " U."
            },
            {
                "end": 111.76,
                "start": 111.62,
                "word": " This"
            },
            {
                "end": 112.16,
                "start": 111.76,
                "word": " function"
            },
            {
                "end": 112.54,
                "start": 112.16,
                "word": " adds"
            },
            {
                "end": 112.78,
                "start": 112.54,
                "word": " two"
            },
            {
                "end": 113.12,
                "start": 112.78,
                "word": " vectors"
            },
            {
                "end": 113.52,
                "start": 113.12,
                "word": " or"
            },
            {
                "end": 113.8,
                "start": 113.52,
                "word": " arrays"
            },
            {
                "end": 114.22,
                "start": 113.8,
                "word": " together."
            },
            {
                "end": 114.6,
                "start": 114.54,
                "word": " It"
            },
            {
                "end": 114.84,
                "start": 114.6,
                "word": " takes"
            },
            {
                "end": 115.18,
                "start": 114.84,
                "word": " pointer"
            },
            {
                "end": 115.6,
                "start": 115.18,
                "word": " arguments"
            },
            {
                "end": 115.9,
                "start": 115.6,
                "word": " A"
            },
            {
                "end": 116.02,
                "start": 115.9,
                "word": " and"
            },
            {
                "end": 116.24,
                "start": 116.02,
                "word": " B,"
            },
            {
                "end": 116.56,
                "start": 116.48,
                "word": " which"
            },
            {
                "end": 116.66,
                "start": 116.56,
                "word": " are"
            },
            {
                "end": 116.74,
                "start": 116.66,
                "word": " the"
            },
            {
                "end": 116.92,
                "start": 116.74,
                "word": " two"
            },
            {
                "end": 117.2,
                "start": 116.92,
                "word": " vectors"
            },
            {
                "end": 117.44,
                "start": 117.2,
                "word": " to"
            },
            {
                "end": 117.56,
                "start": 117.44,
                "word": " be"
            },
            {
                "end": 117.76,
                "start": 117.56,
                "word": " added"
            },
            {
                "end": 118.22,
                "start": 117.76,
                "word": " together,"
            },
            {
                "end": 118.5,
                "start": 118.42,
                "word": " and"
            },
            {
                "end": 118.78,
                "start": 118.5,
                "word": " pointer"
            },
            {
                "end": 119.06,
                "start": 118.78,
                "word": " C"
            },
            {
                "end": 119.32,
                "start": 119.06,
                "word": " for"
            },
            {
                "end": 119.48,
                "start": 119.32,
                "word": " the"
            },
            {
                "end": 119.78,
                "start": 119.48,
                "word": " result."
            },
            {
                "end": 120.18,
                "start": 120,
                "word": " C"
            },
            {
                "end": 120.54,
                "start": 120.18,
                "word": " equals"
            },
            {
                "end": 120.76,
                "start": 120.54,
                "word": " A"
            },
            {
                "end": 120.98,
                "start": 120.76,
                "word": " plus"
            },
            {
                "end": 121.3,
                "start": 120.98,
                "word": " B,"
            },
            {
                "end": 121.64,
                "start": 121.5,
                "word": " but"
            },
            {
                "end": 121.9,
                "start": 121.64,
                "word": " because"
            },
            {
                "end": 122.54,
                "start": 121.9,
                "word": " hypothetically"
            },
            {
                "end": 122.76,
                "start": 122.54,
                "word": " we're"
            },
            {
                "end": 122.96,
                "start": 122.76,
                "word": " doing"
            },
            {
                "end": 123.38,
                "start": 122.96,
                "word": " billions"
            },
            {
                "end": 123.52,
                "start": 123.38,
                "word": " of"
            },
            {
                "end": 123.94,
                "start": 123.52,
                "word": " operations"
            },
            {
                "end": 124.18,
                "start": 123.94,
                "word": " in"
            },
            {
                "end": 124.52,
                "start": 124.18,
                "word": " parallel,"
            },
            {
                "end": 124.88,
                "start": 124.8,
                "word": " we"
            },
            {
                "end": 125,
                "start": 124.88,
                "word": " need"
            },
            {
                "end": 125.14,
                "start": 125,
                "word": " to"
            },
            {
                "end": 125.6,
                "start": 125.14,
                "word": " calculate"
            },
            {
                "end": 125.78,
                "start": 125.6,
                "word": " the"
            },
            {
                "end": 126.02,
                "start": 125.78,
                "word": " global"
            },
            {
                "end": 126.42,
                "start": 126.02,
                "word": " index"
            },
            {
                "end": 126.74,
                "start": 126.42,
                "word": " of"
            },
            {
                "end": 126.9,
                "start": 126.74,
                "word": " the"
            },
            {
                "end": 127.14,
                "start": 126.9,
                "word": " thread"
            },
            {
                "end": 127.38,
                "start": 127.14,
                "word": " and"
            },
            {
                "end": 127.52,
                "start": 127.38,
                "word": " the"
            },
            {
                "end": 127.74,
                "start": 127.52,
                "word": " block"
            },
            {
                "end": 127.96,
                "start": 127.74,
                "word": " that"
            },
            {
                "end": 128.1,
                "start": 127.96,
                "word": " we're"
            },
            {
                "end": 128.36,
                "start": 128.1,
                "word": " working"
            },
            {
                "end": 128.58,
                "start": 128.36,
                "word": " on."
            },
            {
                "end": 128.74,
                "start": 128.66,
                "word": " From"
            },
            {
                "end": 129,
                "start": 128.74,
                "word": " there,"
            },
            {
                "end": 129.22,
                "start": 129,
                "word": " we"
            },
            {
                "end": 129.34,
                "start": 129.22,
                "word": " can"
            },
            {
                "end": 129.54,
                "start": 129.34,
                "word": " use"
            },
            {
                "end": 130.12,
                "start": 129.54,
                "word": " Managed,"
            },
            {
                "end": 130.44,
                "start": 130.28,
                "word": " which"
            },
            {
                "end": 130.62,
                "start": 130.44,
                "word": " tells"
            },
            {
                "end": 131.02,
                "start": 130.62,
                "word": " CUDA"
            },
            {
                "end": 131.28,
                "start": 131.02,
                "word": " this"
            },
            {
                "end": 131.54,
                "start": 131.28,
                "word": " data"
            },
            {
                "end": 131.7,
                "start": 131.54,
                "word": " can"
            },
            {
                "end": 131.84,
                "start": 131.7,
                "word": " be"
            },
            {
                "end": 132.22,
                "start": 131.84,
                "word": " accessed"
            },
            {
                "end": 132.5,
                "start": 132.22,
                "word": " from"
            },
            {
                "end": 132.72,
                "start": 132.5,
                "word": " both"
            },
            {
                "end": 132.84,
                "start": 132.72,
                "word": " the"
            },
            {
                "end": 133,
                "start": 132.84,
                "word": " host"
            },
            {
                "end": 133.36,
                "start": 133,
                "word": " CPU"
            },
            {
                "end": 133.98,
                "start": 133.36,
                "word": " and"
            },
            {
                "end": 134.12,
                "start": 133.98,
                "word": " the"
            },
            {
                "end": 134.4,
                "start": 134.12,
                "word": " device"
            },
            {
                "end": 134.86,
                "start": 134.4,
                "word": " GPU."
            },
            {
                "end": 135.48,
                "start": 135.26,
                "word": " Without"
            },
            {
                "end": 135.64,
                "start": 135.48,
                "word": " the"
            },
            {
                "end": 135.82,
                "start": 135.64,
                "word": " need"
            },
            {
                "end": 136,
                "start": 135.82,
                "word": " to"
            },
            {
                "end": 136.38,
                "start": 136,
                "word": " manually"
            },
            {
                "end": 136.72,
                "start": 136.38,
                "word": " copy"
            },
            {
                "end": 137.06,
                "start": 136.72,
                "word": " data"
            },
            {
                "end": 137.38,
                "start": 137.06,
                "word": " between"
            },
            {
                "end": 137.68,
                "start": 137.38,
                "word": " them,"
            },
            {
                "end": 137.86,
                "start": 137.78,
                "word": " and"
            },
            {
                "end": 138.06,
                "start": 137.86,
                "word": " now"
            },
            {
                "end": 138.18,
                "start": 138.06,
                "word": " we"
            },
            {
                "end": 138.28,
                "start": 138.18,
                "word": " can"
            },
            {
                "end": 138.42,
                "start": 138.28,
                "word": " write"
            },
            {
                "end": 138.52,
                "start": 138.42,
                "word": " a"
            },
            {
                "end": 138.68,
                "start": 138.52,
                "word": " main"
            },
            {
                "end": 139.06,
                "start": 138.68,
                "word": " function"
            },
            {
                "end": 139.26,
                "start": 139.06,
                "word": " for"
            },
            {
                "end": 139.42,
                "start": 139.26,
                "word": " the"
            },
            {
                "end": 139.8,
                "start": 139.42,
                "word": " CPU"
            },
            {
                "end": 140.2,
                "start": 139.8,
                "word": " that"
            },
            {
                "end": 140.48,
                "start": 140.2,
                "word": " runs"
            },
            {
                "end": 140.64,
                "start": 140.48,
                "word": " the"
            },
            {
                "end": 140.86,
                "start": 140.64,
                "word": " CUDA"
            },
            {
                "end": 141.14,
                "start": 140.86,
                "word": " kernel."
            },
            {
                "end": 141.36,
                "start": 141.3,
                "word": " We"
            },
            {
                "end": 141.56,
                "start": 141.36,
                "word": " use"
            },
            {
                "end": 141.7,
                "start": 141.56,
                "word": " a"
            },
            {
                "end": 141.84,
                "start": 141.7,
                "word": " for"
            },
            {
                "end": 142.06,
                "start": 141.84,
                "word": " loop"
            },
            {
                "end": 142.3,
                "start": 142.06,
                "word": " to"
            },
            {
                "end": 142.84,
                "start": 142.3,
                "word": " initialize"
            },
            {
                "end": 142.98,
                "start": 142.84,
                "word": " our"
            },
            {
                "end": 143.24,
                "start": 142.98,
                "word": " arrays"
            },
            {
                "end": 143.46,
                "start": 143.24,
                "word": " with"
            },
            {
                "end": 143.74,
                "start": 143.46,
                "word": " data."
            },
            {
                "end": 144.08,
                "start": 143.92,
                "word": " Then"
            },
            {
                "end": 144.28,
                "start": 144.08,
                "word": " from"
            },
            {
                "end": 144.52,
                "start": 144.28,
                "word": " there"
            },
            {
                "end": 144.82,
                "start": 144.52,
                "word": " we"
            },
            {
                "end": 145.06,
                "start": 144.82,
                "word": " pass"
            },
            {
                "end": 145.32,
                "start": 145.06,
                "word": " this"
            },
            {
                "end": 145.56,
                "start": 145.32,
                "word": " data"
            },
            {
                "end": 145.72,
                "start": 145.56,
                "word": " to"
            },
            {
                "end": 145.84,
                "start": 145.72,
                "word": " the"
            },
            {
                "end": 145.98,
                "start": 145.84,
                "word": " ad"
            },
            {
                "end": 146.38,
                "start": 145.98,
                "word": " function"
            },
            {
                "end": 146.86,
                "start": 146.38,
                "word": " to"
            },
            {
                "end": 147.12,
                "start": 146.86,
                "word": " run"
            },
            {
                "end": 147.24,
                "start": 147.12,
                "word": " it"
            },
            {
                "end": 147.32,
                "start": 147.24,
                "word": " on"
            },
            {
                "end": 147.44,
                "start": 147.32,
                "word": " the"
            },
            {
                "end": 147.8,
                "start": 147.44,
                "word": " GPU."
            },
            {
                "end": 148.32,
                "start": 148.1,
                "word": " But"
            },
            {
                "end": 148.48,
                "start": 148.32,
                "word": " you"
            },
            {
                "end": 148.58,
                "start": 148.48,
                "word": " might"
            },
            {
                "end": 148.72,
                "start": 148.58,
                "word": " be"
            },
            {
                "end": 149.04,
                "start": 148.72,
                "word": " wondering"
            },
            {
                "end": 149.32,
                "start": 149.04,
                "word": " what"
            },
            {
                "end": 149.5,
                "start": 149.32,
                "word": " these"
            },
            {
                "end": 149.72,
                "start": 149.5,
                "word": " weird"
            },
            {
                "end": 150.02,
                "start": 149.72,
                "word": " triple"
            },
            {
                "end": 150.38,
                "start": 150.02,
                "word": " brackets"
            },
            {
                "end": 150.7,
                "start": 150.38,
                "word": " are."
            },
            {
                "end": 150.94,
                "start": 150.86,
                "word": " They"
            },
            {
                "end": 151.14,
                "start": 150.94,
                "word": " allow"
            },
            {
                "end": 151.32,
                "start": 151.14,
                "word": " us"
            },
            {
                "end": 151.4,
                "start": 151.32,
                "word": " to"
            },
            {
                "end": 151.78,
                "start": 151.4,
                "word": " configure"
            },
            {
                "end": 152,
                "start": 151.78,
                "word": " the"
            },
            {
                "end": 152.32,
                "start": 152,
                "word": " CUDA"
            },
            {
                "end": 152.58,
                "start": 152.32,
                "word": " kernel"
            },
            {
                "end": 152.98,
                "start": 152.58,
                "word": " launch"
            },
            {
                "end": 153.18,
                "start": 152.98,
                "word": " to"
            },
            {
                "end": 153.52,
                "start": 153.18,
                "word": " control"
            },
            {
                "end": 153.7,
                "start": 153.52,
                "word": " how"
            },
            {
                "end": 153.88,
                "start": 153.7,
                "word": " many"
            },
            {
                "end": 154.22,
                "start": 153.88,
                "word": " blocks"
            },
            {
                "end": 154.6,
                "start": 154.22,
                "word": " and"
            },
            {
                "end": 154.72,
                "start": 154.6,
                "word": " how"
            },
            {
                "end": 154.88,
                "start": 154.72,
                "word": " many"
            },
            {
                "end": 155.16,
                "start": 154.88,
                "word": " threads"
            },
            {
                "end": 155.4,
                "start": 155.16,
                "word": " per"
            },
            {
                "end": 155.7,
                "start": 155.4,
                "word": " block"
            },
            {
                "end": 155.88,
                "start": 155.7,
                "word": " are"
            },
            {
                "end": 156.12,
                "start": 155.88,
                "word": " used"
            },
            {
                "end": 156.32,
                "start": 156.12,
                "word": " to"
            },
            {
                "end": 156.5,
                "start": 156.32,
                "word": " run"
            },
            {
                "end": 156.68,
                "start": 156.5,
                "word": " this"
            },
            {
                "end": 156.8,
                "start": 156.68,
                "word": " code"
            },
            {
                "end": 156.94,
                "start": 156.8,
                "word": " in"
            },
            {
                "end": 157.26,
                "start": 156.94,
                "word": " parallel."
            },
            {
                "end": 157.46,
                "start": 157.4,
                "word": " And"
            },
            {
                "end": 157.66,
                "start": 157.46,
                "word": " that's"
            },
            {
                "end": 157.96,
                "start": 157.66,
                "word": " crucial"
            },
            {
                "end": 158.16,
                "start": 157.96,
                "word": " for"
            },
            {
                "end": 158.74,
                "start": 158.16,
                "word": " optimizing"
            },
            {
                "end": 159.14,
                "start": 158.74,
                "word": " multi"
            },
            {
                "end": 159.5,
                "start": 159.14,
                "word": "-dimensional"
            },
            {
                "end": 159.82,
                "start": 159.5,
                "word": " data"
            },
            {
                "end": 160.24,
                "start": 159.82,
                "word": " structures"
            },
            {
                "end": 160.74,
                "start": 160.24,
                "word": " like"
            },
            {
                "end": 161.12,
                "start": 160.74,
                "word": " tensors"
            },
            {
                "end": 161.4,
                "start": 161.12,
                "word": " used"
            },
            {
                "end": 161.56,
                "start": 161.4,
                "word": " in"
            },
            {
                "end": 161.74,
                "start": 161.56,
                "word": " deep"
            },
            {
                "end": 162,
                "start": 161.74,
                "word": " learning."
            },
            {
                "end": 162.34,
                "start": 162.22,
                "word": " From"
            },
            {
                "end": 162.62,
                "start": 162.34,
                "word": " there,"
            },
            {
                "end": 163.02,
                "start": 162.9,
                "word": " CUDA"
            },
            {
                "end": 163.28,
                "start": 163.02,
                "word": " device"
            },
            {
                "end": 163.82,
                "start": 163.28,
                "word": " synchronize"
            },
            {
                "end": 164,
                "start": 163.82,
                "word": " will"
            },
            {
                "end": 164.3,
                "start": 164,
                "word": " pause"
            },
            {
                "end": 164.48,
                "start": 164.3,
                "word": " the"
            },
            {
                "end": 164.96,
                "start": 164.48,
                "word": " execution"
            },
            {
                "end": 165.26,
                "start": 164.96,
                "word": " of"
            },
            {
                "end": 165.5,
                "start": 165.26,
                "word": " this"
            },
            {
                "end": 165.76,
                "start": 165.5,
                "word": " code"
            },
            {
                "end": 166.12,
                "start": 165.76,
                "word": " and"
            },
            {
                "end": 166.3,
                "start": 166.12,
                "word": " wait"
            },
            {
                "end": 166.48,
                "start": 166.3,
                "word": " for"
            },
            {
                "end": 166.62,
                "start": 166.48,
                "word": " it"
            },
            {
                "end": 166.7,
                "start": 166.62,
                "word": " to"
            },
            {
                "end": 166.98,
                "start": 166.7,
                "word": " complete"
            },
            {
                "end": 167.16,
                "start": 166.98,
                "word": " on"
            },
            {
                "end": 167.26,
                "start": 167.16,
                "word": " the"
            },
            {
                "end": 167.66,
                "start": 167.26,
                "word": " GPU."
            },
            {
                "end": 168.08,
                "start": 168,
                "word": " When"
            },
            {
                "end": 168.16,
                "start": 168.08,
                "word": " it"
            },
            {
                "end": 168.54,
                "start": 168.16,
                "word": " finishes"
            },
            {
                "end": 168.9,
                "start": 168.54,
                "word": " and"
            },
            {
                "end": 169.26,
                "start": 168.9,
                "word": " copies"
            },
            {
                "end": 169.46,
                "start": 169.26,
                "word": " the"
            },
            {
                "end": 169.66,
                "start": 169.46,
                "word": " data"
            },
            {
                "end": 169.88,
                "start": 169.66,
                "word": " back"
            },
            {
                "end": 170.06,
                "start": 169.88,
                "word": " to"
            },
            {
                "end": 170.12,
                "start": 170.06,
                "word": " the"
            },
            {
                "end": 170.3,
                "start": 170.12,
                "word": " host"
            },
            {
                "end": 170.68,
                "start": 170.3,
                "word": " machine,"
            },
            {
                "end": 170.94,
                "start": 170.86,
                "word": " we"
            },
            {
                "end": 171.04,
                "start": 170.94,
                "word": " can"
            },
            {
                "end": 171.16,
                "start": 171.04,
                "word": " then"
            },
            {
                "end": 171.32,
                "start": 171.16,
                "word": " use"
            },
            {
                "end": 171.46,
                "start": 171.32,
                "word": " the"
            },
            {
                "end": 171.78,
                "start": 171.46,
                "word": " result"
            },
            {
                "end": 172.1,
                "start": 171.78,
                "word": " and"
            },
            {
                "end": 172.36,
                "start": 172.1,
                "word": " print"
            },
            {
                "end": 172.48,
                "start": 172.36,
                "word": " it"
            },
            {
                "end": 172.58,
                "start": 172.48,
                "word": " to"
            },
            {
                "end": 172.68,
                "start": 172.58,
                "word": " the"
            },
            {
                "end": 172.94,
                "start": 172.68,
                "word": " standard"
            },
            {
                "end": 173.28,
                "start": 172.94,
                "word": " output."
            },
            {
                "end": 173.68,
                "start": 173.52,
                "word": " Now,"
            },
            {
                "end": 174.04,
                "start": 173.68,
                "word": " let's"
            },
            {
                "end": 174.38,
                "start": 174.04,
                "word": " execute"
            },
            {
                "end": 174.62,
                "start": 174.38,
                "word": " this"
            },
            {
                "end": 174.82,
                "start": 174.62,
                "word": " code"
            },
            {
                "end": 175,
                "start": 174.82,
                "word": " with"
            },
            {
                "end": 175.06,
                "start": 175,
                "word": " a"
            },
            {
                "end": 175.26,
                "start": 175.06,
                "word": " CUDA"
            },
            {
                "end": 175.76,
                "start": 175.26,
                "word": " compiler"
            },
            {
                "end": 176.06,
                "start": 175.76,
                "word": " by"
            },
            {
                "end": 176.3,
                "start": 176.06,
                "word": " clicking"
            },
            {
                "end": 176.5,
                "start": 176.3,
                "word": " the"
            },
            {
                "end": 176.68,
                "start": 176.5,
                "word": " play"
            },
            {
                "end": 176.94,
                "start": 176.68,
                "word": " button."
            },
            {
                "end": 177.54,
                "start": 177.14,
                "word": " Congratulations,"
            },
            {
                "end": 178.18,
                "start": 178.08,
                "word": " you"
            },
            {
                "end": 178.34,
                "start": 178.18,
                "word": " just"
            },
            {
                "end": 178.48,
                "start": 178.34,
                "word": " ran"
            },
            {
                "end": 179.24,
                "start": 178.48,
                "word": " 256"
            },
            {
                "end": 179.74,
                "start": 179.24,
                "word": " threads"
            },
            {
                "end": 179.94,
                "start": 179.74,
                "word": " and"
            },
            {
                "end": 180.26,
                "start": 179.94,
                "word": " parallel"
            },
            {
                "end": 180.62,
                "start": 180.26,
                "word": " on"
            },
            {
                "end": 180.72,
                "start": 180.62,
                "word": " your"
            },
            {
                "end": 181.16,
                "start": 180.72,
                "word": " GPU."
            },
            {
                "end": 181.6,
                "start": 181.48,
                "word": " But"
            },
            {
                "end": 181.7,
                "start": 181.6,
                "word": " if"
            },
            {
                "end": 181.78,
                "start": 181.7,
                "word": " you"
            },
            {
                "end": 181.9,
                "start": 181.78,
                "word": " want"
            },
            {
                "end": 181.96,
                "start": 181.9,
                "word": " to"
            },
            {
                "end": 182.06,
                "start": 181.96,
                "word": " go"
            },
            {
                "end": 182.38,
                "start": 182.06,
                "word": " beyond,"
            },
            {
                "end": 183.08,
                "start": 182.56,
                "word": " Nvidia's"
            },
            {
                "end": 183.54,
                "start": 183.08,
                "word": " GTC"
            },
            {
                "end": 183.88,
                "start": 183.54,
                "word": " conference"
            },
            {
                "end": 184.1,
                "start": 183.88,
                "word": " is"
            },
            {
                "end": 184.26,
                "start": 184.1,
                "word": " coming"
            },
            {
                "end": 184.46,
                "start": 184.26,
                "word": " up"
            },
            {
                "end": 184.58,
                "start": 184.46,
                "word": " in"
            },
            {
                "end": 184.64,
                "start": 184.58,
                "word": " a"
            },
            {
                "end": 184.78,
                "start": 184.64,
                "word": " few"
            },
            {
                "end": 185.08,
                "start": 184.78,
                "word": " weeks."
            },
            {
                "end": 185.48,
                "start": 185.34,
                "word": " It's"
            },
            {
                "end": 185.64,
                "start": 185.48,
                "word": " free"
            },
            {
                "end": 185.74,
                "start": 185.64,
                "word": " to"
            },
            {
                "end": 185.96,
                "start": 185.74,
                "word": " attend"
            },
            {
                "end": 186.42,
                "start": 185.96,
                "word": " virtually"
            },
            {
                "end": 186.64,
                "start": 186.42,
                "word": " if"
            },
            {
                "end": 186.86,
                "start": 186.64,
                "word": " featuring"
            },
            {
                "end": 187.22,
                "start": 186.86,
                "word": " talks"
            },
            {
                "end": 187.52,
                "start": 187.22,
                "word": " about"
            },
            {
                "end": 187.84,
                "start": 187.52,
                "word": " building"
            },
            {
                "end": 188.28,
                "start": 187.84,
                "word": " massive"
            },
            {
                "end": 188.66,
                "start": 188.28,
                "word": " parallel"
            },
            {
                "end": 189.14,
                "start": 188.66,
                "word": " systems"
            },
            {
                "end": 189.44,
                "start": 189.14,
                "word": " with"
            },
            {
                "end": 189.78,
                "start": 189.44,
                "word": " CUDA."
            },
            {
                "end": 190.14,
                "start": 190,
                "word": " Thanks"
            },
            {
                "end": 190.28,
                "start": 190.14,
                "word": " for"
            },
            {
                "end": 190.62,
                "start": 190.28,
                "word": " watching"
            },
            {
                "end": 190.94,
                "start": 190.62,
                "word": " and"
            },
            {
                "end": 191.08,
                "start": 190.94,
                "word": " I"
            },
            {
                "end": 191.18,
                "start": 191.08,
                "word": " will"
            },
            {
                "end": 191.38,
                "start": 191.18,
                "word": " see"
            },
            {
                "end": 191.54,
                "start": 191.38,
                "word": " you"
            },
            {
                "end": 191.62,
                "start": 191.54,
                "word": " in"
            },
            {
                "end": 191.72,
                "start": 191.62,
                "word": " the"
            },
            {
                "end": 191.9,
                "start": 191.72,
                "word": " next"
            },
            {
                "end": 192.1,
                "start": 191.9,
                "word": " one."
            }
        ]
    },
    "status": "COMPLETED"
}