{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "855482d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '<s> [INST] Instruction [/INST] Model answer</s> [INST] Follow-up instruction [/INST]\\n```diff\\n!pip install transformers\\n!pip install torch\\n\\n!wget https://huggingface.co/distilbert-base-uncased/resolve/main/config.json\\n!wget https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin\\n!wget https://huggingface.co/distilbert-base-uncased/'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"\"\n",
    "headers = {\"Authorization\": \"Bearer \"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"\"\"<s> [INST] Instruction [/INST] Model answer</s> [INST] Follow-up instruction [/INST]\n",
    "\"\"\",\n",
    "})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22eb26c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.runpod.ai/v2/bvcvg7we01985t/status/sync-24251fe2-44ad-446f-8c18-dfe98fa6e862-e1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "url = \"https://api.runpod.ai/v2/\"\n",
    "\n",
    "payload = {\n",
    "    \"input\": {\n",
    "        \"audio\": \"https://github.com/runpod-workers/sample-inputs/raw/main/audio/gettysburg.wav\",\n",
    "        \"model\": \"base\",\n",
    "        \"transcription\": \"srt\",\n",
    "        \"translate\": False,\n",
    "        \"language\": \"en\",\n",
    "        \"temperature\": 0,\n",
    "        \"best_of\": 5,\n",
    "        \"beam_size\": 5,\n",
    "        \"patience\": 1,\n",
    "        \"suppress_tokens\": \"-1\",\n",
    "        \"condition_on_previous_text\": False,\n",
    "        \"temperature_increment_on_fallback\": 0.2,\n",
    "        \"compression_ratio_threshold\": 2.4,\n",
    "        \"logprob_threshold\": -1,\n",
    "        \"no_speech_threshold\": 0.6,\n",
    "        \"word_timestamps\": True\n",
    "    },\n",
    "    \"enable_vad\": False\n",
    "}\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"authorization\": \"\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "url = 'https://api.runpod.ai/v2//status'+ response.json()['id']\n",
    "print(url)\n",
    "while response.json()['status'] != 'COMPLETED':\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.json()['status'] == 'failed':\n",
    "        print(response.json())\n",
    "        break\n",
    "    print(response.json())\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1576c2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'delayTime': 24784, 'executionTime': 2917, 'id': 'sync-24251fe2-44ad-446f-8c18-dfe98fa6e862-e1', 'output': {'detected_language': 'en', 'device': 'cuda', 'model': 'base', 'segments': [{'avg_logprob': -0.18296030405405406, 'compression_ratio': 1.3858267716535433, 'end': 9.8, 'id': 1, 'no_speech_prob': 0.01959228515625, 'seek': 1000, 'start': 0, 'temperature': 0, 'text': ' Four score and seven years ago, our fathers brought forth on this continent a new nation, conceived in liberty, and dedicated to the proposition that all men are created equal.', 'tokens': [50364, 7451, 6175, 293, 3407, 924, 2057, 11, 527, 23450, 3038, 5220, 322, 341, 18932, 257, 777, 4790, 11, 34898, 294, 22849, 11, 293, 8374, 281, 264, 24830, 300, 439, 1706, 366, 2942, 2681, 13, 50864]}], 'transcription': '1\\n00:00:00,000 --> 00:00:09,800\\nFour score and seven years ago, our fathers brought forth on this continent a new nation, conceived in liberty, and dedicated to the proposition that all men are created equal.\\n\\n', 'translation': None, 'word_timestamps': [{'end': 0.6, 'start': 0, 'word': ' Four'}, {'end': 0.96, 'start': 0.6, 'word': ' score'}, {'end': 1.2, 'start': 0.96, 'word': ' and'}, {'end': 1.46, 'start': 1.2, 'word': ' seven'}, {'end': 1.68, 'start': 1.46, 'word': ' years'}, {'end': 2.04, 'start': 1.68, 'word': ' ago,'}, {'end': 2.54, 'start': 2.32, 'word': ' our'}, {'end': 2.92, 'start': 2.54, 'word': ' fathers'}, {'end': 3.26, 'start': 2.92, 'word': ' brought'}, {'end': 3.6, 'start': 3.26, 'word': ' forth'}, {'end': 3.76, 'start': 3.6, 'word': ' on'}, {'end': 3.94, 'start': 3.76, 'word': ' this'}, {'end': 4.36, 'start': 3.94, 'word': ' continent'}, {'end': 4.68, 'start': 4.36, 'word': ' a'}, {'end': 4.8, 'start': 4.68, 'word': ' new'}, {'end': 5.18, 'start': 4.8, 'word': ' nation,'}, {'end': 5.96, 'start': 5.66, 'word': ' conceived'}, {'end': 6.16, 'start': 5.96, 'word': ' in'}, {'end': 6.42, 'start': 6.16, 'word': ' liberty,'}, {'end': 6.78, 'start': 6.74, 'word': ' and'}, {'end': 7.08, 'start': 6.78, 'word': ' dedicated'}, {'end': 7.38, 'start': 7.08, 'word': ' to'}, {'end': 7.48, 'start': 7.38, 'word': ' the'}, {'end': 7.92, 'start': 7.48, 'word': ' proposition'}, {'end': 8.24, 'start': 7.92, 'word': ' that'}, {'end': 8.48, 'start': 8.24, 'word': ' all'}, {'end': 8.7, 'start': 8.48, 'word': ' men'}, {'end': 9, 'start': 8.7, 'word': ' are'}, {'end': 9.38, 'start': 9, 'word': ' created'}, {'end': 9.8, 'start': 9.38, 'word': ' equal.'}]}, 'status': 'COMPLETED'}\n"
     ]
    }
   ],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c7f896d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: {'avg_logprob': -0.18296030405405406, 'compression_ratio': 1.3858267716535433, 'end': 9.8, 'id': 1, 'no_speech_prob': 0.01959228515625, 'seek': 1000, 'start': 0, 'temperature': 0, 'text': ' Four score and seven years ago, our fathers brought forth on this continent a new nation, conceived in liberty, and dedicated to the proposition that all men are created equal.', 'tokens': [50364, 7451, 6175, 293, 3407, 924, 2057, 11, 527, 23450, 3038, 5220, 322, 341, 18932, 257, 777, 4790, 11, 34898, 294, 22849, 11, 293, 8374, 281, 264, 24830, 300, 439, 1706, 366, 2942, 2681, 13, 50864]}\n"
     ]
    }
   ],
   "source": [
    "for index, element in enumerate(response.json()['output']['segments']):\n",
    "    print(f\"Index {index}: {element}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2447e8fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call here. Maybe you meant '==' instead of '='? (3526828431.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 33\u001b[0;36m\u001b[0m\n\u001b[0;31m    response.json()= response_json\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "url = f\"\"\n",
    "\n",
    "headers = {\n",
    "  \"Authorization\":\"\",\n",
    "  \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write me an essay about how the french revolution impacted the rest of europe over the 18th century. \n",
    "\"\"\"\n",
    "\n",
    "payload = {\n",
    "  \"input\": {\n",
    "    \"prompt\": prompt,\n",
    "    \"sampling_params\": {\n",
    "      \"max_tokens\": 1000,\n",
    "      \"n\": 1,\n",
    "      \"presence_penalty\": 0.2,\n",
    "      \"frequency_penalty\": 0.7,\n",
    "      \"temperature\": 0.3,\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "response_json = json.loads(response.text)\n",
    "status_url = f\"https://api.runpod.ai/v2/llama2-13b-chat/stream/{response_json['id']}\"\n",
    "\n",
    "\n",
    "while response.json()['status'] != 'COMPLETED':\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.json()['status'] == 'failed':\n",
    "        print(response.json())\n",
    "        break\n",
    "    print(response.json())\n",
    "    time.sleep(1)\n",
    "\n",
    "\t# example output from print(get_status.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87150130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "headers = {\"Authorization\": \"Bearer \"}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"You are Shlper, a study helper chatbot that answers questions from video transcripts provided by the user. You do not answer any questions other than those related to the given transcript. When answering questions, if the user asks for a reference in the video, you refer to the time frame and answer the question related to that video. Remember every small detail of the transcript; donâ€™t leave out any small details. Remember every word. Do not make up timestep use timestemp given in transcribe.\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9380d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AD65D  AA5C  AA5G  AH37  AH44  AB1  AB17  AB40  AB41  AB18  ...  \\\n",
      "0    1.0  -1.0  -1.0  -1.0   1.0  4.0   2.0  -1.0  -1.0  -1.0  ...   \n",
      "1    2.0  -1.0  -1.0  -1.0  -1.0  2.0   2.0  -1.0  -1.0  -1.0  ...   \n",
      "2    2.0  -1.0  -1.0  -1.0  -1.0  4.0   2.0  -1.0  -1.0  -1.0  ...   \n",
      "3    2.0  -1.0  -1.0   2.0   1.0  1.0   2.0  -1.0  -1.0  -1.0  ...   \n",
      "4    1.0  -1.0  -1.0  -1.0   1.0  2.0   2.0  -1.0  -1.0  -1.0  ...   \n",
      "\n",
      "      RAKEDW71     RAKEDW72     RAKEDW73     RAKEDW74     RAKEDW75  \\\n",
      "0  1658.444734  1638.376110  1630.434441  1665.212727  1643.122217   \n",
      "1   188.508213   185.887002   185.389073   184.864976   188.669543   \n",
      "2   119.401190   118.475142   117.787297   114.842525   118.865641   \n",
      "3   939.370066   964.553991   948.491209   991.097401   993.925372   \n",
      "4   404.033862   408.878539   396.364285   392.332797   400.439376   \n",
      "\n",
      "      RAKEDW76     RAKEDW77     RAKEDW78     RAKEDW79     RAKEDW80  \n",
      "0  1669.670793  1630.330270  1655.333421  1662.627435  1673.809325  \n",
      "1   188.733130   188.577388   190.651613   187.191520   187.050739  \n",
      "2   118.084123   117.082093   115.875362   117.496391   118.728072  \n",
      "3   966.182475   958.987777   951.059390  1888.897010   974.316681  \n",
      "4   406.119226   407.239063   405.714428   390.201501   387.820045  \n",
      "\n",
      "[5 rows x 822 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your SAS file\n",
    "sas_file_path = \"adult.sas7bdat\"\n",
    "\n",
    "# Read SAS file into a DataFrame\n",
    "df = pd.read_sas(sas_file_path)\n",
    "\n",
    "# Print the first 5 rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e7c11343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "\n",
    "url = \"\"\n",
    "def transcribe(filepath):\n",
    "    # Read the content of the audio file and encode it to base64\n",
    "    with open(filepath , \"rb\") as f:\n",
    "        audio_content = f.read()\n",
    "        audio_base64 = base64.b64encode(audio_content).decode(\"utf-8\")\n",
    "\n",
    "    payload = {\n",
    "        \"input\": {\n",
    "            \"audio\": None,\n",
    "            \"audio_base64\": audio_base64,  # Use the base64 encoded content here\n",
    "            \"model\": \"large-v2\",\n",
    "            \"transcription\": \"srt\",\n",
    "            \"translate\": False,\n",
    "            \"language\": \"en\",\n",
    "            \"temperature\": 0,\n",
    "            \"best_of\": 5,\n",
    "            \"beam_size\": 5,\n",
    "            \"patience\": 1,\n",
    "            \"suppress_tokens\": \"-1\",\n",
    "            \"condition_on_previous_text\": False,\n",
    "            \"temperature_increment_on_fallback\": 0.2,\n",
    "            \"compression_ratio_threshold\": 2.4,\n",
    "            \"logprob_threshold\": -1,\n",
    "            \"no_speech_threshold\": 0.6,\n",
    "            \"word_timestamps\": False\n",
    "        },\n",
    "        \"enable_vad\": False\n",
    "    }\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": \"\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "    return(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ad6cb647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['output_000.mp3', 'output_001.mp3', 'output_002.mp3', 'output_003.mp3', 'output_004.mp3', 'output_005.mp3', 'output_006.mp3', 'output_007.mp3', 'output_008.mp3', 'output_009.mp3', 'output_010.mp3', 'output_011.mp3', 'output_012.mp3', 'output_013.mp3', 'output_014.mp3', 'output_015.mp3', 'output_016.mp3', 'output_017.mp3', 'output_018.mp3', 'output_019.mp3', 'output_020.mp3', 'output_021.mp3', 'output_022.mp3', 'output_023.mp3', 'output_024.mp3', 'output_025.mp3', 'output_026.mp3', 'output_027.mp3', 'output_028.mp3', 'output_029.mp3', 'output_030.mp3', 'output_031.mp3']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = os.fsencode(\"./files\")\n",
    "file_list = []\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    file_list.append(filename)\n",
    "\n",
    "file_list_sorted = sorted(file_list)  # Sorting the list in ascending order\n",
    "\n",
    "print(file_list_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c399cbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Can you please let us know more details about your 1997 Chevy K2500 4.3 gas engine?\\n\\nDiagnostics for a slow to start vehicle can involve many steps and in some instances may need professional assistance in order to accurately diagnose the cause. The following checklist and information might help you identify possible causes of this symptom:\\n\\n- Gas tank level: Make sure the vehicle has over 1/4 tank of gas.\\n- Ignition switch: Check for loose connections at the ignition'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6e7421d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1\\n00:00:00,000 --> 00:00:02,240\\nWelcome to the Huberman Lab Podcast,\\n\\n2\\n00:00:02,240 --> 00:00:03,680\\nwhere we discuss science\\n\\n3\\n00:00:03,680 --> 00:00:05,880\\nand science-based tools for everyday life.\\n\\n4\\n00:00:09,200 --> 00:00:10,320\\nI'm Andrew Huberman,\\n\\n5\\n00:00:10,320 --> 00:00:13,440\\nand I'm a professor of neurobiology and ophthalmology\\n\\n6\\n00:00:13,440 --> 00:00:15,520\\nat Stanford School of Medicine.\\n\\n7\\n00:00:15,520 --> 00:00:17,920\\nMy guest today is David Goggins.\\n\\n8\\n00:00:17,920 --> 00:00:20,120\\nDavid Goggins is a retired Navy SEAL\\n\\n9\\n00:00:20,120 --> 00:00:22,560\\nwho served in Iraq and Afghanistan.\\n\\n10\\n00:00:22,560 --> 00:00:26,000\\nHe's also a highly accomplished ultramarathon runner.\\n\\n11\\n00:00:26,000 --> 00:00:27,360\\nFor those of you that don't know,\\n\\n12\\n00:00:27,360 --> 00:00:32,720\\nultramarathons are distances longer than 26 miles, and in David's case, often longer\\n\\n13\\n00:00:32,720 --> 00:00:37,840\\nthan 200 miles. For his achievements in athletics, he has been inducted into the International\\n\\n14\\n00:00:37,840 --> 00:00:43,260\\nSports Hall of Fame. He also held a Guinness World Record for the most pull-ups completed\\n\\n15\\n00:00:43,260 --> 00:00:48,400\\nin 24 hours. I should mention that not only was David a decorated Navy SEAL, but he also\\n\\n16\\n00:00:48,400 --> 00:00:53,840\\ngraduated from Army Ranger School. David is also a highly successful writer, having authored\\n\\n17\\n00:00:53,840 --> 00:00:59,040\\ntwo books, the first entitled Can't Hurt Me and the second entitled Never Finished, both of which\\n\\n18\\n00:00:59,040 --> 00:01:04,640\\nare bestsellers. David's books cover many topics including his autobiographical description\\n\\n19\\n00:01:04,640 --> 00:01:11,280\\nof what can only be described as an incredibly challenging child and young adulthood. His home\\n\\n20\\n00:01:11,280 --> 00:01:16,880\\nwas abusive, his school environment was abusive, he essentially had no positive resources directed\\n\\n21\\n00:01:16,880 --> 00:01:22,880\\nhis way. And in his 20s he found himself to be obese, that is more than 300 pounds working a\\n\\n22\\n00:01:22,880 --> 00:01:30,080\\njob he despised for minimal pay. And it was at that point that David began an inner dialogue\\n\\n23\\n00:01:30,080 --> 00:01:35,280\\nthat forced him to explore the demons born out of his childhood, but also the position that he\\n\\n24\\n00:01:35,280 --> 00:01:41,360\\nfound himself in as a young man, and then began the journey to navigate that dialogue and transform\\n\\n25\\n00:01:41,360 --> 00:01:45,840\\nhimself into the Navy SEAL, the ultramarathon runner, the best-selling author, and the\\n\\n26\\n00:01:45,840 --> 00:01:51,840\\nextraordinarily positive and influential man that he is today. As some of you may know, David has\\n\\n27\\n00:01:51,840 --> 00:01:53,480\\nhas done various public lectures.\\n\\n28\\n00:01:53,480 --> 00:01:55,680\\nHe's a familiar face online\\n\\n29\\n00:01:55,680 --> 00:01:58,640\\nbecause there are so many clips of him on YouTube\\n\\n30\\n00:01:58,640 --> 00:02:00,420\\nand he has done podcasts before.\\n\\n31\\n00:02:00,420 --> 00:02:03,760\\nHowever, I'm certain that you'll find today's discussion\\n\\n32\\n00:02:03,760 --> 00:02:06,520\\nto be very different than previous podcasts\\n\\n33\\n00:02:06,520 --> 00:02:08,640\\nthat David has been featured on.\\n\\n34\\n00:02:08,640 --> 00:02:09,760\\nThe reason is that,\\n\\n35\\n00:02:09,760 --> 00:02:11,500\\nof course we get into his accomplishments.\\n\\n36\\n00:02:11,500 --> 00:02:13,260\\nWe talk about the mindset\\n\\n37\\n00:02:13,260 --> 00:02:15,400\\nthat allowed him to achieve those things.\\n\\n38\\n00:02:15,400 --> 00:02:17,840\\nBut today, David really lets us under the hood.\\n\\n39\\n00:02:17,840 --> 00:02:21,200\\nHe lets us into the form of inner dialogue\\n\\n40\\n00:02:21,200 --> 00:02:22,800\\nthat he has to embrace,\\n\\n41\\n00:02:22,800 --> 00:02:25,360\\nindeed that he has to grapple with on a daily basis,\\n\\n42\\n00:02:25,360 --> 00:02:28,480\\nsometimes multiple times throughout the day and night\\n\\n43\\n00:02:28,480 --> 00:02:31,580\\nin order to impose the sort of self-discipline\\n\\n44\\n00:02:31,580 --> 00:02:33,320\\nthat he is so well-known for.\\n\\n45\\n00:02:33,320 --> 00:02:35,560\\nWe also get into some of the scientific mechanisms\\n\\n46\\n00:02:35,560 --> 00:02:37,040\\nunderlying willpower,\\n\\n47\\n00:02:37,040 --> 00:02:39,420\\nand we talk about David's current endeavors\\n\\n48\\n00:02:39,420 --> 00:02:41,400\\nthat include, for instance,\\n\\n49\\n00:02:41,400 --> 00:02:43,720\\nhis own exploration of science and medicine\\n\\n50\\n00:02:43,720 --> 00:02:47,560\\nfor which he has become an intense scholar and practitioner.\\n\\n51\\n00:02:47,560 --> 00:02:49,840\\nI should mention that multiple times\\n\\n52\\n00:02:49,840 --> 00:02:53,660\\nthroughout today's discussion, you will hear curse words.\\n\\n53\\n00:02:53,660 --> 00:02:54,960\\nNow, David and I both acknowledge\\n\\n54\\n00:02:54,960 --> 00:02:57,180\\nthat cursing isn't for everybody,\\n\\n55\\n00:02:57,180 --> 00:02:59,740\\nand that cursing itself is different\\n\\n56\\n00:02:59,740 --> 00:03:01,760\\nthan cursing at somebody.\\n\\n57\\n00:03:01,760 --> 00:03:05,320\\nNonetheless, we do realize that many people,\\n\\n58\\n00:03:05,320 --> 00:03:09,380\\nparents perhaps especially, might not want to hear cursing.\\n\\n59\\n00:03:09,380 --> 00:03:11,140\\nIf you don't want to hear cursing,\\n\\n60\\n00:03:11,140 --> 00:03:14,620\\nwell then this podcast episode is probably not for you.\\n\\n61\\n00:03:14,620 --> 00:03:16,960\\nHowever, if you are comfortable with cursing\\n\\n62\\n00:03:16,960 --> 00:03:18,500\\nor if you can tolerate it,\\n\\n63\\n00:03:18,500 --> 00:03:22,660\\nI assure you today's discussion is highly worthwhile.\\n\\n64\\n00:03:22,660 --> 00:03:25,420\\nBefore we begin, I'd like to emphasize that this podcast\\n\\n65\\n00:03:25,420 --> 00:03:28,220\\nis separate from my teaching and research roles at Stanford.\\n\\n66\\n00:03:28,220 --> 00:03:30,540\\nIt is, however, part of my desire and effort\\n\\n67\\n00:03:30,540 --> 00:03:32,380\\nto bring zero cost to consumer information\\n\\n68\\n00:03:32,380 --> 00:03:34,500\\nabout science and science-related tools\\n\\n69\\n00:03:34,500 --> 00:03:35,900\\nto the general public.\\n\\n70\\n00:03:35,900 --> 00:03:37,020\\nIn keeping with that theme,\\n\\n71\\n00:03:37,020 --> 00:03:40,000\\nI'd like to thank the sponsors of today's podcast.\\n\\n72\\n00:03:40,000 --> 00:03:42,820\\nOur first sponsor is Maui Nui Venison.\\n\\n73\\n00:03:42,820 --> 00:03:45,260\\nMaui Nui Venison is the most nutrient dense\\n\\n74\\n00:03:45,260 --> 00:03:47,260\\nand delicious red meat available.\\n\\n75\\n00:03:47,260 --> 00:03:49,060\\nI've spoken before on this podcast\\n\\n76\\n00:03:49,060 --> 00:03:50,660\\nand there's general consensus\\n\\n77\\n00:03:50,660 --> 00:03:52,580\\nthat most people should strive to consume\\n\\n78\\n00:03:52,580 --> 00:03:56,860\\napproximately one gram of protein per pound of body weight.\\n\\n79\\n00:03:56,860 --> 00:03:58,640\\nNow, when one strives to do that,\\n\\n80\\n00:03:58,640 --> 00:04:00,620\\nit's important to maximize the quality\\n\\n81\\n00:04:00,620 --> 00:04:03,260\\nof that protein intake to the calorie ratio\\n\\n82\\n00:04:03,260 --> 00:04:05,880\\nbecause you don't want to consume an excess of calories\\n\\n83\\n00:04:05,880 --> 00:04:07,900\\nwhen trying to get that one gram of protein\\n\\n84\\n00:04:07,900 --> 00:04:09,380\\nper pound of body weight.\\n\\n85\\n00:04:09,380 --> 00:04:12,060\\nMaui Nui venison has an extremely high quality protein\\n\\n86\\n00:04:12,060 --> 00:04:13,020\\nto calorie ratio,\\n\\n87\\n00:04:13,020 --> 00:04:14,980\\nSo it makes getting that one gram of protein\\n\\n88\\n00:04:14,980 --> 00:04:17,100\\nper pound of body weight extremely easy.\\n\\n89\\n00:04:17,100 --> 00:04:18,340\\nIt's also delicious.\\n\\n90\\n00:04:18,340 --> 00:04:19,860\\nPersonally, I like the ground venison.\\n\\n91\\n00:04:19,860 --> 00:04:21,420\\nI also like the venison steaks.\\n\\n92\\n00:04:21,420 --> 00:04:24,020\\nAnd then for convenience, when I'm on the road,\\n\\n93\\n00:04:24,020 --> 00:04:25,080\\nI like the jerky.\\n\\n94\\n00:04:25,080 --> 00:04:28,160\\nThe jerky is a very high protein to calorie ratio.\\n\\n95\\n00:04:28,160 --> 00:04:31,380\\nSo it has as much as 10 grams of protein per jerky stick,\\n\\n96\\n00:04:31,380 --> 00:04:33,740\\nand it has something like only like 55 calories.\\n\\n97\\n00:04:33,740 --> 00:04:36,140\\nSo again, making it very easy to get enough protein\\n\\n98\\n00:04:36,140 --> 00:04:38,020\\nwithout consuming excess calories.\\n\\n99\\n00:04:38,020 --> 00:04:40,220\\nIf you would like to try Maui Nui venison,\\n\\n100\\n00:04:40,220 --> 00:04:43,680\\nyou can go to mauinuivenison.com slash Huberman\\n\\n101\\n00:04:43,680 --> 00:04:45,500\\nto get 20% off your first order.\\n\\n102\\n00:04:45,500 --> 00:04:49,020\\nAgain, that's mauinuivenison.com slash Huberman\\n\\n103\\n00:04:49,020 --> 00:04:50,540\\nto get 20% off.\\n\\n104\\n00:04:50,540 --> 00:04:53,500\\nToday's episode is also brought to us by AeroPress.\\n\\n105\\n00:04:53,500 --> 00:04:56,500\\nAeroPress is similar to a French press for making coffee,\\n\\n106\\n00:04:56,500 --> 00:04:59,580\\nbut is in fact a much better way to make coffee.\\n\\n\""
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnscribe_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1b6bb893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final=json.loads(final)\n",
    "type(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "157758f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "00:00:00,000 --> 00:00:02,240\n",
      "Welcome to the Huberman Lab Podcast,\n",
      "\n",
      "2\n",
      "00:00:02,240 --> 00:00:03,680\n",
      "where we discuss science\n",
      "\n",
      "3\n",
      "00:00:03,680 --> 00:00:05,880\n",
      "and science-based tools for everyday life.\n",
      "\n",
      "4\n",
      "00:00:09,200 --> 00:00:10,320\n",
      "I'm Andrew Huberman,\n",
      "\n",
      "5\n",
      "00:00:10,320 --> 00:00:13,440\n",
      "and I'm a professor of neurobiology and ophthalmology\n",
      "\n",
      "6\n",
      "00:00:13,440 --> 00:00:15,520\n",
      "at Stanford School of Medicine.\n",
      "\n",
      "7\n",
      "00:00:15,520 --> 00:00:17,920\n",
      "My guest today is David Goggins.\n",
      "\n",
      "8\n",
      "00:00:17,920 --> 00:00:20,120\n",
      "David Goggins is a retired Navy SEAL\n",
      "\n",
      "9\n",
      "00:00:20,120 --> 00:00:22,560\n",
      "who served in Iraq and Afghanistan.\n",
      "\n",
      "10\n",
      "00:00:22,560 --> 00:00:26,000\n",
      "He's also a highly accomplished ultramarathon runner.\n",
      "\n",
      "11\n",
      "00:00:26,000 --> 00:00:27,360\n",
      "For those of you that don't know,\n",
      "\n",
      "12\n",
      "00:00:27,360 --> 00:00:32,720\n",
      "ultramarathons are distances longer than 26 miles, and in David's case, often longer\n",
      "\n",
      "13\n",
      "00:00:32,720 --> 00:00:37,840\n",
      "than 200 miles. For his achievements in athletics, he has been inducted into the International\n",
      "\n",
      "14\n",
      "00:00:37,840 --> 00:00:43,260\n",
      "Sports Hall of Fame. He also held a Guinness World Record for the most pull-ups completed\n",
      "\n",
      "15\n",
      "00:00:43,260 --> 00:00:48,400\n",
      "in 24 hours. I should mention that not only was David a decorated Navy SEAL, but he also\n",
      "\n",
      "16\n",
      "00:00:48,400 --> 00:00:53,840\n",
      "graduated from Army Ranger School. David is also a highly successful writer, having authored\n",
      "\n",
      "17\n",
      "00:00:53,840 --> 00:00:59,040\n",
      "two books, the first entitled Can't Hurt Me and the second entitled Never Finished, both of which\n",
      "\n",
      "18\n",
      "00:00:59,040 --> 00:01:04,640\n",
      "are bestsellers. David's books cover many topics including his autobiographical description\n",
      "\n",
      "19\n",
      "00:01:04,640 --> 00:01:11,280\n",
      "of what can only be described as an incredibly challenging child and young adulthood. His home\n",
      "\n",
      "20\n",
      "00:01:11,280 --> 00:01:16,880\n",
      "was abusive, his school environment was abusive, he essentially had no positive resources directed\n",
      "\n",
      "21\n",
      "00:01:16,880 --> 00:01:22,880\n",
      "his way. And in his 20s he found himself to be obese, that is more than 300 pounds working a\n",
      "\n",
      "22\n",
      "00:01:22,880 --> 00:01:30,080\n",
      "job he despised for minimal pay. And it was at that point that David began an inner dialogue\n",
      "\n",
      "23\n",
      "00:01:30,080 --> 00:01:35,280\n",
      "that forced him to explore the demons born out of his childhood, but also the position that he\n",
      "\n",
      "24\n",
      "00:01:35,280 --> 00:01:41,360\n",
      "found himself in as a young man, and then began the journey to navigate that dialogue and transform\n",
      "\n",
      "25\n",
      "00:01:41,360 --> 00:01:45,840\n",
      "himself into the Navy SEAL, the ultramarathon runner, the best-selling author, and the\n",
      "\n",
      "26\n",
      "00:01:45,840 --> 00:01:51,840\n",
      "extraordinarily positive and influential man that he is today. As some of you may know, David has\n",
      "\n",
      "27\n",
      "00:01:51,840 --> 00:01:53,480\n",
      "has done various public lectures.\n",
      "\n",
      "28\n",
      "00:01:53,480 --> 00:01:55,680\n",
      "He's a familiar face online\n",
      "\n",
      "29\n",
      "00:01:55,680 --> 00:01:58,640\n",
      "because there are so many clips of him on YouTube\n",
      "\n",
      "30\n",
      "00:01:58,640 --> 00:02:00,420\n",
      "and he has done podcasts before.\n",
      "\n",
      "31\n",
      "00:02:00,420 --> 00:02:03,760\n",
      "However, I'm certain that you'll find today's discussion\n",
      "\n",
      "32\n",
      "00:02:03,760 --> 00:02:06,520\n",
      "to be very different than previous podcasts\n",
      "\n",
      "33\n",
      "00:02:06,520 --> 00:02:08,640\n",
      "that David has been featured on.\n",
      "\n",
      "34\n",
      "00:02:08,640 --> 00:02:09,760\n",
      "The reason is that,\n",
      "\n",
      "35\n",
      "00:02:09,760 --> 00:02:11,500\n",
      "of course we get into his accomplishments.\n",
      "\n",
      "36\n",
      "00:02:11,500 --> 00:02:13,260\n",
      "We talk about the mindset\n",
      "\n",
      "37\n",
      "00:02:13,260 --> 00:02:15,400\n",
      "that allowed him to achieve those things.\n",
      "\n",
      "38\n",
      "00:02:15,400 --> 00:02:17,840\n",
      "But today, David really lets us under the hood.\n",
      "\n",
      "39\n",
      "00:02:17,840 --> 00:02:21,200\n",
      "He lets us into the form of inner dialogue\n",
      "\n",
      "40\n",
      "00:02:21,200 --> 00:02:22,800\n",
      "that he has to embrace,\n",
      "\n",
      "41\n",
      "00:02:22,800 --> 00:02:25,360\n",
      "indeed that he has to grapple with on a daily basis,\n",
      "\n",
      "42\n",
      "00:02:25,360 --> 00:02:28,480\n",
      "sometimes multiple times throughout the day and night\n",
      "\n",
      "43\n",
      "00:02:28,480 --> 00:02:31,580\n",
      "in order to impose the sort of self-discipline\n",
      "\n",
      "44\n",
      "00:02:31,580 --> 00:02:33,320\n",
      "that he is so well-known for.\n",
      "\n",
      "45\n",
      "00:02:33,320 --> 00:02:35,560\n",
      "We also get into some of the scientific mechanisms\n",
      "\n",
      "46\n",
      "00:02:35,560 --> 00:02:37,040\n",
      "underlying willpower,\n",
      "\n",
      "47\n",
      "00:02:37,040 --> 00:02:39,420\n",
      "and we talk about David's current endeavors\n",
      "\n",
      "48\n",
      "00:02:39,420 --> 00:02:41,400\n",
      "that include, for instance,\n",
      "\n",
      "49\n",
      "00:02:41,400 --> 00:02:43,720\n",
      "his own exploration of science and medicine\n",
      "\n",
      "50\n",
      "00:02:43,720 --> 00:02:47,560\n",
      "for which he has become an intense scholar and practitioner.\n",
      "\n",
      "51\n",
      "00:02:47,560 --> 00:02:49,840\n",
      "I should mention that multiple times\n",
      "\n",
      "52\n",
      "00:02:49,840 --> 00:02:53,660\n",
      "throughout today's discussion, you will hear curse words.\n",
      "\n",
      "53\n",
      "00:02:53,660 --> 00:02:54,960\n",
      "Now, David and I both acknowledge\n",
      "\n",
      "54\n",
      "00:02:54,960 --> 00:02:57,180\n",
      "that cursing isn't for everybody,\n",
      "\n",
      "55\n",
      "00:02:57,180 --> 00:02:59,740\n",
      "and that cursing itself is different\n",
      "\n",
      "56\n",
      "00:02:59,740 --> 00:03:01,760\n",
      "than cursing at somebody.\n",
      "\n",
      "57\n",
      "00:03:01,760 --> 00:03:05,320\n",
      "Nonetheless, we do realize that many people,\n",
      "\n",
      "58\n",
      "00:03:05,320 --> 00:03:09,380\n",
      "parents perhaps especially, might not want to hear cursing.\n",
      "\n",
      "59\n",
      "00:03:09,380 --> 00:03:11,140\n",
      "If you don't want to hear cursing,\n",
      "\n",
      "60\n",
      "00:03:11,140 --> 00:03:14,620\n",
      "well then this podcast episode is probably not for you.\n",
      "\n",
      "61\n",
      "00:03:14,620 --> 00:03:16,960\n",
      "However, if you are comfortable with cursing\n",
      "\n",
      "62\n",
      "00:03:16,960 --> 00:03:18,500\n",
      "or if you can tolerate it,\n",
      "\n",
      "63\n",
      "00:03:18,500 --> 00:03:22,660\n",
      "I assure you today's discussion is highly worthwhile.\n",
      "\n",
      "64\n",
      "00:03:22,660 --> 00:03:25,420\n",
      "Before we begin, I'd like to emphasize that this podcast\n",
      "\n",
      "65\n",
      "00:03:25,420 --> 00:03:28,220\n",
      "is separate from my teaching and research roles at Stanford.\n",
      "\n",
      "66\n",
      "00:03:28,220 --> 00:03:30,540\n",
      "It is, however, part of my desire and effort\n",
      "\n",
      "67\n",
      "00:03:30,540 --> 00:03:32,380\n",
      "to bring zero cost to consumer information\n",
      "\n",
      "68\n",
      "00:03:32,380 --> 00:03:34,500\n",
      "about science and science-related tools\n",
      "\n",
      "69\n",
      "00:03:34,500 --> 00:03:35,900\n",
      "to the general public.\n",
      "\n",
      "70\n",
      "00:03:35,900 --> 00:03:37,020\n",
      "In keeping with that theme,\n",
      "\n",
      "71\n",
      "00:03:37,020 --> 00:03:40,000\n",
      "I'd like to thank the sponsors of today's podcast.\n",
      "\n",
      "72\n",
      "00:03:40,000 --> 00:03:42,820\n",
      "Our first sponsor is Maui Nui Venison.\n",
      "\n",
      "73\n",
      "00:03:42,820 --> 00:03:45,260\n",
      "Maui Nui Venison is the most nutrient dense\n",
      "\n",
      "74\n",
      "00:03:45,260 --> 00:03:47,260\n",
      "and delicious red meat available.\n",
      "\n",
      "75\n",
      "00:03:47,260 --> 00:03:49,060\n",
      "I've spoken before on this podcast\n",
      "\n",
      "76\n",
      "00:03:49,060 --> 00:03:50,660\n",
      "and there's general consensus\n",
      "\n",
      "77\n",
      "00:03:50,660 --> 00:03:52,580\n",
      "that most people should strive to consume\n",
      "\n",
      "78\n",
      "00:03:52,580 --> 00:03:56,860\n",
      "approximately one gram of protein per pound of body weight.\n",
      "\n",
      "79\n",
      "00:03:56,860 --> 00:03:58,640\n",
      "Now, when one strives to do that,\n",
      "\n",
      "80\n",
      "00:03:58,640 --> 00:04:00,620\n",
      "it's important to maximize the quality\n",
      "\n",
      "81\n",
      "00:04:00,620 --> 00:04:03,260\n",
      "of that protein intake to the calorie ratio\n",
      "\n",
      "82\n",
      "00:04:03,260 --> 00:04:05,880\n",
      "because you don't want to consume an excess of calories\n",
      "\n",
      "83\n",
      "00:04:05,880 --> 00:04:07,900\n",
      "when trying to get that one gram of protein\n",
      "\n",
      "84\n",
      "00:04:07,900 --> 00:04:09,380\n",
      "per pound of body weight.\n",
      "\n",
      "85\n",
      "00:04:09,380 --> 00:04:12,060\n",
      "Maui Nui venison has an extremely high quality protein\n",
      "\n",
      "86\n",
      "00:04:12,060 --> 00:04:13,020\n",
      "to calorie ratio,\n",
      "\n",
      "87\n",
      "00:04:13,020 --> 00:04:14,980\n",
      "So it makes getting that one gram of protein\n",
      "\n",
      "88\n",
      "00:04:14,980 --> 00:04:17,100\n",
      "per pound of body weight extremely easy.\n",
      "\n",
      "89\n",
      "00:04:17,100 --> 00:04:18,340\n",
      "It's also delicious.\n",
      "\n",
      "90\n",
      "00:04:18,340 --> 00:04:19,860\n",
      "Personally, I like the ground venison.\n",
      "\n",
      "91\n",
      "00:04:19,860 --> 00:04:21,420\n",
      "I also like the venison steaks.\n",
      "\n",
      "92\n",
      "00:04:21,420 --> 00:04:24,020\n",
      "And then for convenience, when I'm on the road,\n",
      "\n",
      "93\n",
      "00:04:24,020 --> 00:04:25,080\n",
      "I like the jerky.\n",
      "\n",
      "94\n",
      "00:04:25,080 --> 00:04:28,160\n",
      "The jerky is a very high protein to calorie ratio.\n",
      "\n",
      "95\n",
      "00:04:28,160 --> 00:04:31,380\n",
      "So it has as much as 10 grams of protein per jerky stick,\n",
      "\n",
      "96\n",
      "00:04:31,380 --> 00:04:33,740\n",
      "and it has something like only like 55 calories.\n",
      "\n",
      "97\n",
      "00:04:33,740 --> 00:04:36,140\n",
      "So again, making it very easy to get enough protein\n",
      "\n",
      "98\n",
      "00:04:36,140 --> 00:04:38,020\n",
      "without consuming excess calories.\n",
      "\n",
      "99\n",
      "00:04:38,020 --> 00:04:40,220\n",
      "If you would like to try Maui Nui venison,\n",
      "\n",
      "100\n",
      "00:04:40,220 --> 00:04:43,680\n",
      "you can go to mauinuivenison.com slash Huberman\n",
      "\n",
      "101\n",
      "00:04:43,680 --> 00:04:45,500\n",
      "to get 20% off your first order.\n",
      "\n",
      "102\n",
      "00:04:45,500 --> 00:04:49,020\n",
      "Again, that's mauinuivenison.com slash Huberman\n",
      "\n",
      "103\n",
      "00:04:49,020 --> 00:04:50,540\n",
      "to get 20% off.\n",
      "\n",
      "104\n",
      "00:04:50,540 --> 00:04:53,500\n",
      "Today's episode is also brought to us by AeroPress.\n",
      "\n",
      "105\n",
      "00:04:53,500 --> 00:04:56,500\n",
      "AeroPress is similar to a French press for making coffee,\n",
      "\n",
      "106\n",
      "00:04:56,500 --> 00:04:59,580\n",
      "but is in fact a much better way to make coffee.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final['output']['transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7478b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.srt\", \"w\") as file:\n",
    "    file.write(final['output']['transcription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "edd6f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet, re\n",
    "\n",
    "filenames = [\"output.srt\", \"output copy.srt\"]\n",
    "encodings = []\n",
    "for name in filenames:\n",
    "    with open(name, \"br\") as file:\n",
    "        encodings.append(chardet.detect(file.read())[\"encoding\"])\n",
    "\n",
    "re_sub_no = re.compile(r\"^\\d+\\s*$\", re.MULTILINE)\n",
    "\n",
    "def repl(match):\n",
    "    global sub_no\n",
    "    sub_no += 1\n",
    "    return str(sub_no)\n",
    "\n",
    "sub_no = 0\n",
    "with open(\"sub_merged.srt\", \"w\", encoding=encodings[0]) as fout:\n",
    "    for name, encoding in zip(filenames, encodings):\n",
    "        with open(name, \"r\", encoding=encoding) as fin:\n",
    "            fout.write(re_sub_no.sub(repl, fin.read()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
